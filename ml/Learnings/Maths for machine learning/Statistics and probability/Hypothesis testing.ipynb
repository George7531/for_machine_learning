{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc7bc2c",
   "metadata": {},
   "source": [
    "# day 130 and day 131 and day 132 and day 134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73900427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sym\n",
    "from IPython.display import display,Math\n",
    "sym.init_printing()\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89558d5",
   "metadata": {},
   "source": [
    "# model \n",
    "\n",
    "# $$ h = \\beta_1 s + \\beta_2 p + \\beta_3 n + e $$\n",
    "\n",
    "h is height\n",
    "\n",
    "s is sex\n",
    "\n",
    "p is parents' height\n",
    "\n",
    "n is childhood nutrition\n",
    "\n",
    "e is residual\n",
    "\n",
    "\n",
    "# target,accuracy, errors and sin(pavam):\n",
    "\n",
    "target = 1\n",
    "\n",
    "accuracy = 1 - errors\n",
    "\n",
    "errors = 1 - accuracy\n",
    "\n",
    "sin = error\n",
    "\n",
    "# Hypothesis Testing:\n",
    "\n",
    "**progress in science,technology,mathematics and medicine come from testing many hypotheses**\n",
    "\n",
    "\n",
    "### not an hypothesis:\n",
    "\n",
    "medical research is important for curing diseases\n",
    "\n",
    "\n",
    "### a weak hypothesis:\n",
    "\n",
    "\"the medicine has an effect\" this statement is a weak hypothesis because the medicine might have negative effect or positive effect or any kind of iatrogenic (short-term pain releaving and long-term ass kicking) effect. so this statement has be refined further with specificity(specific descriptions need to be provided).\n",
    "\n",
    "\n",
    "### a strong hypothesis:\n",
    "\n",
    "the medicine reduces symptom X in a dose-response fashion. \n",
    "\n",
    "\n",
    "# understandings:\n",
    "**Time is our friend to help us get closer to the Truth**.\n",
    "\n",
    "1. Be as much **specific** as possible when forming hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12be68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "611a7827",
   "metadata": {},
   "source": [
    "# Sample Distributions under null and alternative hypothesis:\n",
    "\n",
    " $$ \\frac{\\text{difference in centers of distibutions of } H_{0} \\text{ and } H_{A}} {\\text{widths of distributions} } = \\frac{\\text{Signal}}{\\text{Noise}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91cb0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c41135ea",
   "metadata": {},
   "source": [
    "# P-values\n",
    "\n",
    "# What is a P-value?\n",
    "\n",
    "1.  the probability of the alternative hypothesis being True given that Null hypothesis is True. $$p(H_{A}|H_{0}) $$ is what the P-value trying to solve. \n",
    "\n",
    "\n",
    "\n",
    "2.  p value is a threshold to reject null hypothesis and accept alternative hypothesis once the probability of occurence of alternative hypotheis being True given that null hypothesis is True is large enough.\n",
    "\n",
    "\n",
    "\n",
    "3.  how far away the alternative hypothesis line falls from the centre(mean) of the null hypothesis distribution is what the p value is all about.\n",
    "\n",
    "\n",
    "# P-values:\n",
    "\n",
    "* P-values closer to zero: p(Ha|Ho) is low\n",
    "* p-values closer to 1: p(Ha|Ho) is high\n",
    "\n",
    "# the difference between the previous statistics course i took and mike cohen's statistics is:\n",
    "\n",
    "* In the previous course: Null hypothesis is hypothesis we need to works towards and alternative hypothesis is the baseline assumption.\n",
    "\n",
    "* In mike cohen's course: Null hypothesis is baseline assumption and alternative hypothesis is the assumption we need to work towards.\n",
    "\n",
    "\n",
    "# stastical significance:\n",
    "* P-value < 0.05 or 0.01 are considered common values.\n",
    "\n",
    "# examples:\n",
    "* if p value is 0.02: there's a 2% chance that there is no effect. but 98% chance that there is an effect.\n",
    "\n",
    "* if p value is 0.05: there's a 5% chance that there is no effect, but 95% chance there is an effect.\n",
    "\n",
    "* if p value is 0.00001: there is 0.001% chance that there is no effect, but 99.99% chance that there is an effect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ca4ccbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24012089",
   "metadata": {},
   "source": [
    "# % of distribution of data in a normal dist (MEMORIZE !)\n",
    "1. 68.3% of the data falls within 1 std.\n",
    "2. 95.5% of the data falls within 2 std.\n",
    "3. 99.7% of the data falls within 3 std.\n",
    "\n",
    "# p value and Z score for a one-tailed test (MEMORIZE !)\n",
    "1. when p value is 0.05, z score is 1.64.\n",
    "2. when p value is 0.01, z score is 2.32.\n",
    "3. when p value is 0.001, z score is 3.09.\n",
    "\n",
    "\n",
    "# p value and z score for a two-tailed test (MEMORIZE!)\n",
    "$$ \\text{1. when p value is 0.05,  Z score is }\\pm1.96. \\text{(95% of data on both sides)} $$\n",
    "$$ \\text{2. when p value is 0.01,  Z score is }\\pm2.58. \\text{(99% of data on both sides) } $$\n",
    "$$ \\text{3. when p value is 0.001, Z score is }\\pm3.29. \\text{(99.9% of data on both sides)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c4ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd269cf6",
   "metadata": {},
   "source": [
    "# degrees of freedom:\n",
    "\n",
    "* degrees of freedom counts how many independent variables in a list of variables.\n",
    "\n",
    "* degrees of freedom is how much freedom a variable has. if a variable has 0 degrees of freedom then it could take on no more than one value. it is forever enslaved to bearing that value. it cannot escape the grasp of its depressive fate. i.e 5 = (1+2+3+x)/4 = x = 14. x is forever enslaved to bearing 14 nothing else in this case! but if 5 = (1+2+y+x)/4 = x can take infinite number of values. the degree of freedom for x here is infinity. it is not enslave to any particular fate. the number of combination of fate the 'x' can be subjected to is infinite.\n",
    "\n",
    "* this analysis 5 = (x+y+z+u)/4 has 3 degrees of freedom because if you know value for three elements in the equation then you'd bet you know your fourth value. which means that three variables in the equation say, x,y,z, has infinite possibilities to have any values to satisfy the equation but the fourth variable say,u, doesn't have any freedom once all the previous variables',x,y,z, values are known. u is enslaved if x,y,z choose their independent values before u could.\n",
    "\n",
    "* but if it was a sample distribution, x,y,z,u are in sample distribuition, and the mean is population mean then the degrees of freedom would be 4 because the sample mean is not as same as the population mean.\n",
    "\n",
    "* in mechanics degrees of freedom is determined by how many ways a thing can move.\n",
    "\n",
    "# clear understaning and implications:\n",
    "* degrees of freedom(df) determine the shape of the null hypothesis distribution.\n",
    "* higher degrees of freedom means you have more power(statistical power) to reject the null hypothesis.\n",
    "* degrees of freedom is also a way for checking ANOVA table for accuracy and understanding.\n",
    "* degrees of freedom explains how many varibales in a dataset that are unconstrained by the other varible's values. \n",
    "\n",
    "# formula:\n",
    "\n",
    "degrees of freedom  = N-K\n",
    "where N is number of data points\n",
    "K is number of variable/parameters/features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4741668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbf3dafb",
   "metadata": {},
   "source": [
    "# Type 1 and Type 2 Errors:\n",
    "\n",
    "\n",
    "1.  if we increase the statistical significance level and in an effort to reduce one type of Error we may increase the other type of Error so striking a balance is impediment.\n",
    "\n",
    "\n",
    "\n",
    "2. the most important thing is we have to decrease the type 1 and type 2 errors by increasing the distance between the null hypothesis and alternative hypothesis. in other words reduce the noise in signal/noise ratio. we can achieve this by comparing something that's obviously different like the height of giraffe and a height of a human instead of height of south african giraffes and height of northen african giraffes\n",
    "\n",
    "\n",
    "3. second thing to note to reduce the type 1 and type 2 errors is having the width of the distribution of null hypothesis and alternative hypothesis narrower like increasing their kurtosis and making them look like leptokurtic, this way we can ensure to have Type 1 and Type 2 dramatically reduced\n",
    "\n",
    "# conclusion:\n",
    "\n",
    "1. Make the distributions of null hypothesis and alternative hypothesis as more narrower(leptokurtic) and far apart(distant centres) as possible. They should not overlap much!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5869b441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "980ce868",
   "metadata": {},
   "source": [
    "# Parametric and Non-parametric statistics: \n",
    "\n",
    "\n",
    "# Non-parametric statistic:\n",
    "\n",
    "1. it is typically about relaxing the guassian procedures in our methods when handling data allowing for data to speak for itself instead of having assumptions like 'all distributions are guassian','law of large numbers hold True in all places of the Universe', 'most-people are middle-class' and so on. so basically it is about letting go of our models and embrace the reality of the Universe as it is(even though it is not entirely True we still use tests/models to understand the reality even in non-parametric case).\n",
    "\n",
    "\n",
    "\n",
    "| S.No | Parametric Tests    | Non-Parametric Tests      |\n",
    "|------|---------------------|-------------------------  |\n",
    "| 1    | 1-sample t-test     | Wilcoxon signed-rank test |\n",
    "| 2    | 2-sample t-test     | Mann-Whitney U test       |\n",
    "| 3    | Pearson correlation | Spearman correlation      |\n",
    "| 4    | ANOVA               | Kruskal-Wallis test       |\n",
    "\n",
    "\n",
    "\n",
    "# application of non-parametric tests:\n",
    "\n",
    "1. permutation-testing \n",
    "\n",
    "2. cross validation.\n",
    "\n",
    "3. randomness\n",
    "\n",
    "# when to use what?\n",
    "\n",
    "1. use non-parametric tests on data if the data is really small\n",
    "\n",
    "2. use parametric tests when the data is large enough!\n",
    "\n",
    "3. when you are dealing with randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d702cee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "996a6534",
   "metadata": {},
   "source": [
    "# family wise error rate\n",
    "\n",
    "# maximum family wise error rate:\n",
    "\n",
    "# $$ \\text{FWE } \\le n*\\alpha $$\n",
    "\n",
    "# $$ \\alpha - \\text{statistical significance or p value} $$\n",
    "\n",
    "# $$ n - \\text{number of tests } $$\n",
    "\n",
    "\n",
    "# problem:\n",
    "\n",
    "* it may increase the probability of getting more type 1 errors (False Positives) \n",
    "\n",
    "\n",
    "\n",
    "# how to tackle it?\n",
    "\n",
    "0. apply bonferroni corrected p value: pvalue/n\n",
    "\n",
    "\n",
    "\n",
    "1. Be conservative! have the statistical significance(p value) as low as possible.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. Have the distributions of null hypothesis and alternative hypothesis distant (their centers need to be as far apart as possible) this can be achieved only if we calculate the statistics of something that are obviously different i.e height of humans and giraffe. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3. Have the distributions of null hypothesis and alternative hypothesis as narrower as possible (leptokurtic).One way is to add outliers to the distribution. Outliers are data points that are much higher or lower than the rest of the data. Adding outliers will make the distribution more peaked.Another way to make a distribution leptokurtic is to reduce the variance of the distribution. The variance of a distribution is a measure of how spread out the data is. Reducing the variance will make the distribution more concentrated around the mean, which will make it more peaked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a7c01a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ff4561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e783df58",
   "metadata": {},
   "source": [
    "# p-value:\n",
    "\n",
    "\n",
    "* Tests the probability of the sample statistic to occur by chance.\n",
    "\n",
    "* can be computed seperately for each parameter of the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a4cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
