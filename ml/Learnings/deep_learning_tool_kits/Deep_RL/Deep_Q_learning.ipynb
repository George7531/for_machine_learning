{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMnKZPht6DvGww3xs1Y1tG1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"917e3d7db1cc499e8eb23b890b57522c":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_061f7696eba048c79e68c37185979d33","IPY_MODEL_2faad385ac4344b7bfd81a1ae12b03d4","IPY_MODEL_c34208ca867242ffad430c5dc7ec95ba","IPY_MODEL_fe3dc12d28e8421ab91494d68585ce35"],"layout":"IPY_MODEL_ca6113873544454ca688f17359d0b010"}},"d85981ec931741b8b8a57ba31b361204":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58d3b8929d79495d9b38229c85436bc6","placeholder":"​","style":"IPY_MODEL_55ce120e8a0440c3b86810f020d592d0","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"4094376eb3074f1796aec1018c029fff":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_e0898acaad7a4bfea9e7b188bcc70dc2","placeholder":"​","style":"IPY_MODEL_550fa2ddca2b48f8a21a29f38db8e850","value":""}},"315adadd8d3342b79699ce4e51ff7b33":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_e656de3304404456b212eec1a231de56","style":"IPY_MODEL_3eef8bc8bc864c4a860d905d3e40dfff","value":true}},"45f86d04ed914234b6a20e8f4ef4100a":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_6ea3cdda16ff4018bef011003e63f976","style":"IPY_MODEL_29ff26b50b4f4a1ca7c8c6dd632fc86f","tooltip":""}},"1db52c63f7f0461aa4c6503d01d8ecf6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_772571ca903d4da8bbcf0fd19e83d4e3","placeholder":"​","style":"IPY_MODEL_70c645c7cf5241b297fdcf1ef62e57e4","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"ca6113873544454ca688f17359d0b010":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"58d3b8929d79495d9b38229c85436bc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55ce120e8a0440c3b86810f020d592d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0898acaad7a4bfea9e7b188bcc70dc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"550fa2ddca2b48f8a21a29f38db8e850":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e656de3304404456b212eec1a231de56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3eef8bc8bc864c4a860d905d3e40dfff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ea3cdda16ff4018bef011003e63f976":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29ff26b50b4f4a1ca7c8c6dd632fc86f":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"772571ca903d4da8bbcf0fd19e83d4e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70c645c7cf5241b297fdcf1ef62e57e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59752a1b9dda486bbd04bca367f35b45":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8990f1e4dadf4d34a08cee583ecb8885","placeholder":"​","style":"IPY_MODEL_47f70941685d495696efc58e9e834edf","value":"Connecting..."}},"8990f1e4dadf4d34a08cee583ecb8885":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47f70941685d495696efc58e9e834edf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"061f7696eba048c79e68c37185979d33":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9194497629647a78d0f71862ce9aa17","placeholder":"​","style":"IPY_MODEL_9d6ee07350164dbab5c645028b950aee","value":"Token is valid (permission: write)."}},"2faad385ac4344b7bfd81a1ae12b03d4":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b17ed949a88415583e83158f7ca4461","placeholder":"​","style":"IPY_MODEL_bb8b73caceee4e239822d6ff1a1837ae","value":"Your token has been saved in your configured git credential helpers (store)."}},"c34208ca867242ffad430c5dc7ec95ba":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf35d14dc62c4076bef905e7d8d2b570","placeholder":"​","style":"IPY_MODEL_aa2478e43bb640bfa7c8fd06f7de491b","value":"Your token has been saved to /root/.cache/huggingface/token"}},"fe3dc12d28e8421ab91494d68585ce35":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6f56e5c6ac5421e8f6289c7d9cb8143","placeholder":"​","style":"IPY_MODEL_c76db16b5a8743b2b25ed3258a77dd5e","value":"Login successful"}},"d9194497629647a78d0f71862ce9aa17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d6ee07350164dbab5c645028b950aee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b17ed949a88415583e83158f7ca4461":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb8b73caceee4e239822d6ff1a1837ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf35d14dc62c4076bef905e7d8d2b570":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa2478e43bb640bfa7c8fd06f7de491b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6f56e5c6ac5421e8f6289c7d9cb8143":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c76db16b5a8743b2b25ed3258a77dd5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# day 369,370"],"metadata":{"id":"8oTwL4sRXrZ8"}},{"cell_type":"markdown","source":["![fsfs](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/thumbnail.jpg)\n","\n","* We got excellent results with this simple algorithm, but these environments were relatively simple because the state space was discrete and small (16 different states for FrozenLake-v1 and 500 for Taxi-v3). For comparison, the state space in Atari games can contain $10^9 $ to $10^{11}$ states.\n","* But as we’ll see, producing and updating a Q-table can become ineffective in large state space environments.\n","* So in this unit, we’ll study our first Deep Reinforcement Learning agent: Deep Q-Learning. Instead of using a Q-table, Deep Q-Learning uses a Neural Network that takes a state and approximates Q-values for each action based on that state.\n","* And we’ll train it to play Space Invaders and other Atari environments using RL-Zoo, a training framework for RL using Stable-Baselines that provides scripts for training, evaluating agents, tuning hyperparameters, plotting results, and recording videos.\n","![sfsf](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/atari-envs.gif)"],"metadata":{"id":"Hq1j981KXw7g"}},{"cell_type":"code","source":[],"metadata":{"id":"xhE4XDU1bNyq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# from Q-learning to deep Q-learning\n","\n","* We learned that Q-Learning is an algorithm we use to train our Q-Function, an action-value function that determines the value of being at a particular state and taking a specific action at that state.\n","\n","![fsdf](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/Q-function.jpg)\n","\n","* The Q comes from “the Quality” of that action at that state.\n","\n","* The Q comes from “the Quality” of that action at that state.\n","\n","* Internally, our Q-function is encoded by a Q-table, a table where each cell corresponds to a state-action pair value. Think of this Q-table as the memory or cheat sheet of our Q-function.\n","\n","* The problem is that Q-Learning is a tabular method. This becomes a problem if the states and actions spaces are not small enough to be represented efficiently by arrays and tables. In other words: it is not scalable. Q-Learning worked well with small state space environments like:\n","\n","* FrozenLake, we had 16 states.\n","Taxi-v3, we had 500 states.\n","But think of what we’re going to do today: we will train an agent to learn to play Space Invaders, a more complex game, using the frames as input.\n","\n","* As Nikita Melkozerov mentioned, Atari environments have an observation space with a shape of (210, 160, 3)*, containing values ranging from 0 to 255 so that gives us\n","$256^{210×160×3}=256^{100800}$ possible observations (for comparison, we have approximately $ 10^{80}$ atoms in the observable universe).\n","* A single frame in Atari is composed of an image of 210x160 pixels. Given that the images are in color (RGB), there are 3 channels. This is why the shape is (210, 160, 3). For each pixel, the value can go from 0 to 255.\n","![sfsdf](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/atari.jpg)\n","\n","\n","* Therefore, the state space is gigantic; due to this, creating and updating a Q-table for that environment would not be efficient. In this case, the best idea is to approximate the Q-values using a parametrized Q-function $ 𝑄_𝜃(𝑠,𝑎) $\n","\n","This neural network will approximate, given a state, the different Q-values for each possible action at that state. And that’s exactly what Deep Q-Learning does.\n","![sfs](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit1/deep.jpg)\n","\n"],"metadata":{"id":"5d5yR-82Xw-K"}},{"cell_type":"code","source":[],"metadata":{"id":"xKj3YS5kh0AC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WzZWATNKbqvu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Deep Q-network (DQN):\n","\n","![sfsd](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/deep-q-network.jpg)\n","\n","* As input, we take a stack of 4 frames passed through the network as a state and output a vector of Q-values for each possible action at that state. Then, like with Q-Learning, we just need to use our epsilon-greedy policy to select which action to take.\n","\n","* When the Neural Network is initialized, the Q-value estimation is terrible. But during training, our Deep Q-Network agent will associate a situation with the appropriate action and learn to play the game well.\n","\n","## Preprocessing the input and temporal limitation:\n","* We need to preprocess the input. It’s an essential step since we want to reduce the complexity of our state to reduce the computation time needed for training.\n","\n","* To achieve this, we reduce the state space to 84x84 and grayscale it. We can do this since the colors in Atari environments don’t add important information. This is a big improvement since we reduce our three color channels (RGB) to 1.\n","\n","* We can also crop a part of the screen in some games if it does not contain important information. Then we stack four frames together.\n","\n","![fsfs](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/preprocessing.jpg)\n","\n","## why we stack 4 images together?\n","\n","* Why do we stack four frames together? We stack frames together because it helps us handle the problem of temporal limitation. Let’s take an example with the game of Pong. When you see this frame:\n","\n","![sfsfs](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/temporal-limitation.jpg)\n","\n","* Can you tell me where the ball is going? No, because one frame is not enough to have a sense of motion! But what if I add three more frames? Here you can see that the ball is going to the right.\n","\n","![fsf](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/temporal-limitation-2.jpg)\n","\n","* That’s why, to capture temporal information, we stack four frames together.\n","\n","* Then the stacked frames are processed by three convolutional layers. These layers allow us to capture and exploit spatial relationships in images. But also, because the frames are stacked together, we can exploit some temporal properties across those frames.\n","\n","* Finally, we have a couple of fully connected layers that output a Q-value for each possible action at that state.\n","\n","![sfsdf](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/deep-q-network.jpg)\n","\n","* So, we see that Deep Q-Learning uses a neural network to approximate, given a state, the different Q-values for each possible action at that state. Now let’s study the Deep Q-Learning algorithm."],"metadata":{"id":"9Rg2ddWIjRAG"}},{"cell_type":"code","source":[],"metadata":{"id":"C6s-LEY_n3l-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# The Deep Q-learning Algorithm studies:\n","\n","* We learned that Deep Q-Learning uses a deep neural network to approximate the different Q-values for each possible action at a state (value-function estimation).\n","\n","* The difference is that, during the training phase, instead of updating the Q-value of a state-action pair directly as we have done with Q-Learning:\n","\n","![fsdffs](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/q-ex-5.jpg)\n","\n","* in Deep Q-Learning, we create a loss function that compares our Q-value prediction and the Q-target and uses gradient descent to update the weights of our Deep Q-Network to approximate our Q-values better.\n","\n","![fssfsd](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/Q-target.jpg)\n","\n","The Deep Q-Learning training algorithm has two phases:\n","\n","1. Sampling: we perform actions and store the observed experience tuples in a replay memory.\n","\n","2. Training: Select a small batch of tuples randomly and learn from this batch using a gradient descent update step.\n","\n","![sfsf](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/sampling-training.jpg)\n","\n","* This is not the only difference compared with Q-Learning. Deep Q-Learning training might suffer from instability, mainly because of combining a non-linear Q-value function (Neural Network) and bootstrapping (when we update targets with existing estimates and not an actual complete return).\n","\n","* To help us stabilize the training, we implement three different solutions:\n","\n","* Experience Replay to make more efficient use of experiences.\n","* Fixed Q-Target to stabilize the training.\n","* Double Deep Q-Learning, to handle the problem of the overestimation of Q-values.\n","\n","\n","## Experience replays to make efficient use of experiences:\n","\n","* Why do we create a replay memory?\n","\n","* Experience Replay in Deep Q-Learning has two functions:\n","\n","1. Make more efficient use of the experiences during the training. Usually, in online reinforcement learning, the agent interacts with the environment, gets experiences (state, action, reward, and next state), learns from them (updates the neural network), and discards them. This is not efficient.\n","Experience replay helps by using the experiences of the training more efficiently. We use a replay buffer that saves experience samples that we can reuse during the training.\n","![ffsdf](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/experience-replay.jpg)\n","* This allows the agent to learn from the same experiences multiple times.\n","* This is like using ANKI to revise the old experiences(information) instead of simply discarding them after just a study session(like most learners do).\n","\n","\n","2. Avoid forgetting previous experiences (aka catastrophic interference, or catastrophic forgetting) and reduce the correlation between experiences.\n","\n","* catastrophic forgetting: The problem we get if we give sequential samples of experiences to our neural network is that it tends to forget the previous experiences as it gets new experiences. For instance, if the agent is in the first level and then in the second, which is different, it can forget how to behave and play in the first level.\n","The solution is to create a Replay Buffer that stores experience tuples while interacting with the environment and then sample a small batch of tuples. This prevents the network from only learning about what it has done immediately before.\n","\n","* Experience replay also has other benefits. By randomly sampling the experiences, we remove correlation in the observation sequences and avoid action values from oscillating or diverging catastrophically.\n","\n","* In the Deep Q-Learning pseudocode, we initialize a replay memory buffer D with capacity N (N is a hyperparameter that you can define). We then store experiences in the memory and sample a batch of experiences to feed the Deep Q-Network during the training phase.\n","\n","![fsfs](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/experience-replay-pseudocode.jpg)\n","\n","\n","## Fixed Q-target to stabilize the learning:\n","\n","* When we want to calculate the TD error (aka the loss), we calculate the difference between the TD target (Q-Target) and the current Q-value (estimation of Q).\n","\n","* But we don’t have any idea of the real TD target. We need to estimate it. Using the Bellman equation, we saw that the TD target is just the reward of taking that action at that state plus the discounted highest Q value for the next state.\n","\n","![fss](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/Q-target.jpg)\n","\n","* However, the problem is that we are using the same parameters (weights) for estimating the TD target and the Q-value. Consequently, there is a significant correlation between the TD target and the parameters we are changing.\n","\n","* Therefore, at every step of training, both our Q-values and the target values shift. We’re getting closer to our target, but the target is also moving. It’s like chasing a moving target! This can lead to significant oscillation in training.\n","\n","* It’s like if you were a cowboy (the Q estimation) and you wanted to catch a cow (the Q-target). Your goal is to get closer (reduce the error).\n","\n","![fss](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/qtarget-1.jpg)\n","\n","* At each time step, you’re trying to approach the cow, which also moves at each time step (because you use the same parameters).\n","\n","![fsfs](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/qtarget-2.jpg)\n","\n","![sfsd](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/qtarget-3.jpg)\n","\n","* This leads to a bizarre path of chasing (a significant oscillation in training).\n","\n","![fsfs](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/qtarget-4.jpg)\n","\n","* Instead, what we see in the pseudo-code is that we:\n","\n","1. Use a separate network with fixed parameters for estimating the TD Target\n","2. Copy the parameters from our Deep Q-Network every C steps to update the target network.\n","\n","![fssd](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/fixed-q-target-pseudocode.jpg)\n","\n","\n","## Double DQN:\n","\n","* Double DQNs, or Double Deep Q-Learning neural networks, were introduced by Hado van Hasselt. This method handles the problem of the overestimation of Q-values.\n","\n","* To understand this problem, remember how we calculate the TD Target:\n","\n","![fsfsd](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit3/TD-1.jpg)\n","\n","* We face a simple problem by calculating the TD target: how are we sure that the best action for the next state is the action with the highest Q-value?\n","\n","* We know that the accuracy of Q-values depends on what action we tried and what neighboring states we explored.\n","\n","* Consequently, we don’t have enough information about the best action to take at the beginning of the training. Therefore, taking the maximum Q-value (which is noisy) as the best action to take can lead to false positives. If non-optimal actions are regularly given a higher Q value than the optimal best action, the learning will be complicated.\n","\n","* The solution is: when we compute the Q target, we use two networks to decouple the action selection from the target Q-value generation. We:\n","\n","* Use our DQN network to select the best action to take for the next state (the action with the highest Q-value).\n","\n","* Use our Target network to calculate the target Q-value of taking that action at the next state.\n","\n","* Therefore, Double DQN helps us reduce the overestimation of Q-values and, as a consequence, helps us train faster and with more stable learning.\n","\n","* Since these three improvements in Deep Q-Learning, many more have been added, such as Prioritized Experience Replay and Dueling Deep Q-Learning. They’re out of the scope of this course but if you’re interested, check the links we put in the reading list.\n"],"metadata":{"id":"TlGFj4krjRC-"}},{"cell_type":"code","source":[],"metadata":{"id":"OYoOgkNWw-BK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hands-on"],"metadata":{"id":"Cwgm0t_wjRGc"}},{"cell_type":"markdown","source":["![sfsf](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/thumbnail.jpg)\n","\n","* In this notebook, you'll train a Deep Q-Learning agent playing Space Invaders using RL Baselines3 Zoo, a training framework based on Stable-Baselines3 that provides scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos.\n","\n","\n","## the end result:\n","![sdfsdf](https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/atari-envs.gif)"],"metadata":{"id":"7Nrb631KbqyR"}},{"cell_type":"code","source":[],"metadata":{"id":"6BXy6JH73da6","executionInfo":{"status":"ok","timestamp":1715348771922,"user_tz":-330,"elapsed":5,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# For now we install this update of RL-Baselines3 Zoo\n","!pip install git+https://github.com/DLR-RM/rl-baselines3-zoo@update/hf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LAoAmqQU2-JX","executionInfo":{"status":"ok","timestamp":1715350464125,"user_tz":-330,"elapsed":152039,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}},"outputId":"ebc57b40-ee5e-4dc1-8323-23abb8de3be9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/DLR-RM/rl-baselines3-zoo@update/hf\n","  Cloning https://github.com/DLR-RM/rl-baselines3-zoo (to revision update/hf) to /tmp/pip-req-build-7ijbzzlh\n","  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/rl-baselines3-zoo /tmp/pip-req-build-7ijbzzlh\n","  Running command git checkout -b update/hf --track origin/update/hf\n","  Switched to a new branch 'update/hf'\n","  Branch 'update/hf' set up to track remote branch 'update/hf' from 'origin'.\n","  Resolved https://github.com/DLR-RM/rl-baselines3-zoo to commit 7dcbff7e74e7a12c052452181ff353a4dbed313a\n","  Running command git submodule update --init --recursive -q\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting sb3-contrib>=2.0.0a9 (from rl_zoo3==2.0.0a9)\n","  Downloading sb3_contrib-2.3.0-py3-none-any.whl (80 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gym==0.26.2 (from rl_zoo3==2.0.0a9)\n","  Downloading gym-0.26.2.tar.gz (721 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting huggingface-sb3>=2.2.1 (from rl_zoo3==2.0.0a9)\n","  Downloading huggingface_sb3-3.0-py3-none-any.whl (9.7 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from rl_zoo3==2.0.0a9) (4.66.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from rl_zoo3==2.0.0a9) (13.7.1)\n","Collecting optuna (from rl_zoo3==2.0.0a9)\n","  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from rl_zoo3==2.0.0a9) (6.0.1)\n","Collecting pytablewriter~=0.64 (from rl_zoo3==2.0.0a9)\n","  Downloading pytablewriter-0.64.2-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2->rl_zoo3==2.0.0a9) (1.25.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2->rl_zoo3==2.0.0a9) (2.2.1)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2->rl_zoo3==2.0.0a9) (0.0.8)\n","Requirement already satisfied: huggingface-hub~=0.8 in /usr/local/lib/python3.10/dist-packages (from huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (0.20.3)\n","Requirement already satisfied: wasabi in /usr/local/lib/python3.10/dist-packages (from huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (1.1.2)\n","Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter~=0.64->rl_zoo3==2.0.0a9) (67.7.2)\n","Collecting DataProperty<2,>=0.55.0 (from pytablewriter~=0.64->rl_zoo3==2.0.0a9)\n","  Downloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n","Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter~=0.64->rl_zoo3==2.0.0a9)\n","  Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n","Collecting pathvalidate<3,>=2.3.0 (from pytablewriter~=0.64->rl_zoo3==2.0.0a9)\n","  Downloading pathvalidate-2.5.2-py3-none-any.whl (20 kB)\n","Collecting tabledata<2,>=1.3.0 (from pytablewriter~=0.64->rl_zoo3==2.0.0a9)\n","  Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n","Collecting tcolorpy<1,>=0.0.5 (from pytablewriter~=0.64->rl_zoo3==2.0.0a9)\n","  Downloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\n","Collecting typepy[datetime]<2,>=1.2.0 (from pytablewriter~=0.64->rl_zoo3==2.0.0a9)\n","  Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n","Collecting stable-baselines3<3.0,>=2.3.0 (from sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n","  Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting alembic>=1.5.0 (from optuna->rl_zoo3==2.0.0a9)\n","  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorlog (from optuna->rl_zoo3==2.0.0a9)\n","  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna->rl_zoo3==2.0.0a9) (24.0)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->rl_zoo3==2.0.0a9) (2.0.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->rl_zoo3==2.0.0a9) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->rl_zoo3==2.0.0a9) (2.16.1)\n","Collecting Mako (from alembic>=1.5.0->optuna->rl_zoo3==2.0.0a9)\n","  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->rl_zoo3==2.0.0a9) (4.11.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (2.31.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->rl_zoo3==2.0.0a9) (0.1.2)\n","Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter~=0.64->rl_zoo3==2.0.0a9) (5.2.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->rl_zoo3==2.0.0a9) (3.0.3)\n","Collecting gymnasium<0.30,>=0.28.1 (from stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n","  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (2.2.1+cu121)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (2.0.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (3.7.1)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.2.0->pytablewriter~=0.64->rl_zoo3==2.0.0a9) (2.8.2)\n","Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.2.0->pytablewriter~=0.64->rl_zoo3==2.0.0a9) (2023.4)\n","Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.8.0->typepy[datetime]<2,>=1.2.0->pytablewriter~=0.64->rl_zoo3==2.0.0a9) (1.16.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna->rl_zoo3==2.0.0a9) (2.1.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (3.1.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3>=2.2.1->rl_zoo3==2.0.0a9) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3<3.0,>=2.3.0->sb3-contrib>=2.0.0a9->rl_zoo3==2.0.0a9) (1.3.0)\n","Building wheels for collected packages: rl_zoo3, gym\n","  Building wheel for rl_zoo3 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rl_zoo3: filename=rl_zoo3-2.0.0a9-py3-none-any.whl size=76402 sha256=95e0d680d09cbf64c687ab68b9f938f927ef3e829581453744b274996a9372a3\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-8m08d64h/wheels/fc/36/d5/2ef574649d85327de098075c8523da50be2612f3e5807261f7\n","  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827623 sha256=46138407b247aae2f7d466792a1510da18a89aae9162c905c5e1341c1709cd72\n","  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n","Successfully built rl_zoo3 gym\n","Installing collected packages: farama-notifications, tcolorpy, pathvalidate, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mbstrdecoder, Mako, gymnasium, gym, colorlog, typepy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, alembic, optuna, nvidia-cusolver-cu12, huggingface-sb3, DataProperty, tabledata, stable-baselines3, sb3-contrib, pytablewriter, rl_zoo3\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.25.2\n","    Uninstalling gym-0.25.2:\n","      Successfully uninstalled gym-0.25.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","dopamine-rl 4.0.9 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed DataProperty-1.0.1 Mako-1.3.3 alembic-1.13.1 colorlog-6.8.2 farama-notifications-0.0.4 gym-0.26.2 gymnasium-0.29.1 huggingface-sb3-3.0 mbstrdecoder-1.1.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 optuna-3.6.1 pathvalidate-2.5.2 pytablewriter-0.64.2 rl_zoo3-2.0.0a9 sb3-contrib-2.3.0 stable-baselines3-2.3.2 tabledata-1.3.3 tcolorpy-0.1.6 typepy-1.3.2\n"]}]},{"cell_type":"code","source":["!apt-get install swig cmake ffmpeg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKgIC-RY9k3D","executionInfo":{"status":"ok","timestamp":1715350470821,"user_tz":-330,"elapsed":6702,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}},"outputId":"b0ab337b-71ce-4f63-c2c0-3d43fcd8ff96"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","The following additional packages will be installed:\n","  swig4.0\n","Suggested packages:\n","  swig-doc swig-examples swig4.0-examples swig4.0-doc\n","The following NEW packages will be installed:\n","  swig swig4.0\n","0 upgraded, 2 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 1,116 kB of archives.\n","After this operation, 5,542 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n","Fetched 1,116 kB in 2s (744 kB/s)\n","Selecting previously unselected package swig4.0.\n","(Reading database ... 121918 files and directories currently installed.)\n","Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n","Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n","Selecting previously unselected package swig.\n","Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n","Unpacking swig (4.0.2-1ubuntu1) ...\n","Setting up swig4.0 (4.0.2-1ubuntu1) ...\n","Setting up swig (4.0.2-1ubuntu1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n"]}]},{"cell_type":"code","source":["'''# To be able to use Atari games in Gymnasium we need to install atari package.\n","And accept-rom-license to download the rom files (games files).'''\n","\n","!pip install gymnasium[atari]\n","!pip install gymnasium[accept-rom-license]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e0M1RQer27Hh","executionInfo":{"status":"ok","timestamp":1715350495193,"user_tz":-330,"elapsed":24376,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}},"outputId":"a49fd0ee-6337-47ee-b7ff-852bd1b743dd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (1.25.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (4.11.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[atari]) (0.0.4)\n","Collecting shimmy[atari]<1.0,>=0.1.0 (from gymnasium[atari])\n","  Downloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\n","Collecting ale-py~=0.8.1 (from shimmy[atari]<1.0,>=0.1.0->gymnasium[atari])\n","  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0->gymnasium[atari]) (6.4.0)\n","Installing collected packages: ale-py, shimmy\n","Successfully installed ale-py-0.8.1 shimmy-0.2.1\n","Requirement already satisfied: gymnasium[accept-rom-license] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (1.25.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (4.11.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license]) (0.0.4)\n","Collecting autorom[accept-rom-license]~=0.4.2 (from gymnasium[accept-rom-license])\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (8.1.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (4.66.4)\n","Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license])\n","  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (2024.2.2)\n","Building wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446659 sha256=9e4f49ef5c71d1533983a5ba7a647905f38a10f003c0d43339edef741432c4b3\n","  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: AutoROM.accept-rom-license, autorom\n","Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.4.2\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"a-gVitir_1go"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create a virtual display 🔽\n","\n","During the notebook, we'll need to generate a replay video. To do so, with colab, **we need to have a virtual screen to be able to render the environment** (and thus record the frames).\n","\n","Hence the following cell will install the librairies and create and run a virtual screen 🖥"],"metadata":{"id":"UHMlydhHBEPK"}},{"cell_type":"code","source":["%%capture\n","!apt install python-opengl\n","!apt install xvfb\n","!pip3 install pyvirtualdisplay"],"metadata":{"id":"MXMF8YwmBGEu","executionInfo":{"status":"ok","timestamp":1715350513218,"user_tz":-330,"elapsed":18048,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from pyvirtualdisplay import Display\n","\n","virtual_display = Display(visible=0, size=(1400,900))\n","virtual_display.start()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vEn7vXtGBTXA","executionInfo":{"status":"ok","timestamp":1715350513984,"user_tz":-330,"elapsed":772,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}},"outputId":"8096201c-545a-4b17-8f74-8afdec86f6db"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyvirtualdisplay.display.Display at 0x7bcf7c219f00>"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":[],"metadata":{"id":"AFQPKr_WCAlo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train our Deep Q-Learning Agent to Play Space Invaders 👾\n","\n","To train an agent with RL-Baselines3-Zoo, we just need to do two things:\n","\n","1. Create a hyperparameter config file that will contain our training hyperparameters called `dqn.yml`.\n","\n","This is a template example:\n","\n","```\n","SpaceInvadersNoFrameskip-v4:\n","  env_wrapper:\n","    - stable_baselines3.common.atari_wrappers.AtariWrapper\n","  frame_stack: 4\n","  policy: 'CnnPolicy'\n","  n_timesteps: !!float 1e6\n","  buffer_size: 100000\n","  learning_rate: !!float 1e-4\n","  batch_size: 32\n","  learning_starts: 100000\n","  target_update_interval: 1000\n","  train_freq: 4\n","  gradient_steps: 1\n","  exploration_fraction: 0.1\n","  exploration_final_eps: 0.01\n","  # If True, you need to deactivate handle_timeout_termination\n","  # in the replay_buffer_kwargs\n","  optimize_memory_usage: False\n","```"],"metadata":{"id":"zoSNyQWUCAon"}},{"cell_type":"code","source":["!touch dqn.yml"],"metadata":{"id":"_Ww4r_sUzHyU","executionInfo":{"status":"ok","timestamp":1715350513985,"user_tz":-330,"elapsed":8,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dqQC2gKMCArW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here we see that:\n","- We use the `Atari Wrapper` that preprocess the input (Frame reduction ,grayscale, stack 4 frames)\n","- We use `CnnPolicy`, since we use Convolutional layers to process the frames\n","- We train it for 10 million `n_timesteps`\n","- Memory (Experience Replay) size is 100000, aka the amount of experience steps you saved to train again your agent with.\n","\n","💡 My advice is to **reduce the training timesteps to 1M,** which will take about 90 minutes on a P100. `!nvidia-smi` will tell you what GPU you're using. At 10 million steps, this will take about 9 hours, which could likely result in Colab timing out. I recommend running this on your local computer (or somewhere else). Just click on: `File>Download`."],"metadata":{"id":"0RQJfLUDCAuZ"}},{"cell_type":"code","source":[],"metadata":{"id":"kKef-iadEQLH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In terms of hyperparameters optimization, my advice is to focus on these 3 hyperparameters:\n","- `learning_rate`:  (float | Callable[[float], float]) – The learning rate, it can be a function of the current progress remaining (from 1 to 0)\n","- `buffer_size (Experience Memory size)`: size of the replay buffer\n","- `batch_size`: Minibatch size for each gradient update\n","\n","As a good practice, you need to **check the documentation to understand what each hyperparameters does**: https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html#parameters\n"],"metadata":{"id":"KyGtLNOWEQNp"}},{"cell_type":"code","source":[],"metadata":{"id":"-_0UK2ZNITAA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. We start the training and save the models on `logs` folder 📁\n","\n","- Define the algorithm after `--algo`, where we save the model after `-f` and where the hyperparameter config is after `-c`."],"metadata":{"id":"bLza6JMdITDI"}},{"cell_type":"code","source":["!mkdir logs"],"metadata":{"id":"S1s1IsSW1xDb","executionInfo":{"status":"ok","timestamp":1715350513985,"user_tz":-330,"elapsed":6,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["!python -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/  -c dqn.yml"],"metadata":{"id":"fQsYcObzEQQp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715354598587,"user_tz":-330,"elapsed":4021895,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}},"outputId":"6b19bcaa-a533-46cf-e3cf-12579d85b756"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.72e+03 |\n","|    ep_rew_mean      | 345      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2732     |\n","|    fps              | 267      |\n","|    time_elapsed     | 2067     |\n","|    total_timesteps  | 552298   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0701   |\n","|    n_updates        | 113074   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.71e+03 |\n","|    ep_rew_mean      | 346      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2736     |\n","|    fps              | 267      |\n","|    time_elapsed     | 2070     |\n","|    total_timesteps  | 553035   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0387   |\n","|    n_updates        | 113258   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.72e+03 |\n","|    ep_rew_mean      | 349      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2740     |\n","|    fps              | 267      |\n","|    time_elapsed     | 2074     |\n","|    total_timesteps  | 554225   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0708   |\n","|    n_updates        | 113556   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.71e+03 |\n","|    ep_rew_mean      | 346      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2744     |\n","|    fps              | 267      |\n","|    time_elapsed     | 2077     |\n","|    total_timesteps  | 554949   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0217   |\n","|    n_updates        | 113737   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.72e+03 |\n","|    ep_rew_mean      | 348      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2748     |\n","|    fps              | 267      |\n","|    time_elapsed     | 2080     |\n","|    total_timesteps  | 555793   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0546   |\n","|    n_updates        | 113948   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.71e+03 |\n","|    ep_rew_mean      | 347      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2752     |\n","|    fps              | 267      |\n","|    time_elapsed     | 2084     |\n","|    total_timesteps  | 556552   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0118   |\n","|    n_updates        | 114137   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.72e+03 |\n","|    ep_rew_mean      | 346      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2756     |\n","|    fps              | 267      |\n","|    time_elapsed     | 2087     |\n","|    total_timesteps  | 557503   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0246   |\n","|    n_updates        | 114375   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.72e+03 |\n","|    ep_rew_mean      | 346      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2760     |\n","|    fps              | 267      |\n","|    time_elapsed     | 2091     |\n","|    total_timesteps  | 558611   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.032    |\n","|    n_updates        | 114652   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.71e+03 |\n","|    ep_rew_mean      | 344      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2764     |\n","|    fps              | 266      |\n","|    time_elapsed     | 2097     |\n","|    total_timesteps  | 559999   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0409   |\n","|    n_updates        | 114999   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.72e+03 |\n","|    ep_rew_mean      | 347      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2768     |\n","|    fps              | 266      |\n","|    time_elapsed     | 2101     |\n","|    total_timesteps  | 561149   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0235   |\n","|    n_updates        | 115287   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.76e+03 |\n","|    ep_rew_mean      | 352      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2772     |\n","|    fps              | 267      |\n","|    time_elapsed     | 2105     |\n","|    total_timesteps  | 562267   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0264   |\n","|    n_updates        | 115566   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.76e+03 |\n","|    ep_rew_mean      | 353      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2776     |\n","|    fps              | 266      |\n","|    time_elapsed     | 2110     |\n","|    total_timesteps  | 563356   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0265   |\n","|    n_updates        | 115838   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.77e+03 |\n","|    ep_rew_mean      | 358      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2780     |\n","|    fps              | 266      |\n","|    time_elapsed     | 2112     |\n","|    total_timesteps  | 563927   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.029    |\n","|    n_updates        | 115981   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.77e+03 |\n","|    ep_rew_mean      | 354      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2784     |\n","|    fps              | 266      |\n","|    time_elapsed     | 2116     |\n","|    total_timesteps  | 564911   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0246   |\n","|    n_updates        | 116227   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.78e+03 |\n","|    ep_rew_mean      | 355      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2788     |\n","|    fps              | 266      |\n","|    time_elapsed     | 2119     |\n","|    total_timesteps  | 565777   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0176   |\n","|    n_updates        | 116444   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.78e+03 |\n","|    ep_rew_mean      | 353      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2792     |\n","|    fps              | 266      |\n","|    time_elapsed     | 2123     |\n","|    total_timesteps  | 566735   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0407   |\n","|    n_updates        | 116683   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.78e+03 |\n","|    ep_rew_mean      | 355      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2796     |\n","|    fps              | 266      |\n","|    time_elapsed     | 2126     |\n","|    total_timesteps  | 567662   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0291   |\n","|    n_updates        | 116915   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.78e+03 |\n","|    ep_rew_mean      | 355      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2800     |\n","|    fps              | 266      |\n","|    time_elapsed     | 2130     |\n","|    total_timesteps  | 568616   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0305   |\n","|    n_updates        | 117153   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.76e+03 |\n","|    ep_rew_mean      | 352      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2804     |\n","|    fps              | 266      |\n","|    time_elapsed     | 2134     |\n","|    total_timesteps  | 569728   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0337   |\n","|    n_updates        | 117431   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.79e+03 |\n","|    ep_rew_mean      | 355      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2808     |\n","|    fps              | 266      |\n","|    time_elapsed     | 2138     |\n","|    total_timesteps  | 570770   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0144   |\n","|    n_updates        | 117692   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.79e+03 |\n","|    ep_rew_mean      | 356      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2812     |\n","|    fps              | 266      |\n","|    time_elapsed     | 2142     |\n","|    total_timesteps  | 571732   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0234   |\n","|    n_updates        | 117932   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.8e+03  |\n","|    ep_rew_mean      | 356      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2816     |\n","|    fps              | 266      |\n","|    time_elapsed     | 2146     |\n","|    total_timesteps  | 572838   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0163   |\n","|    n_updates        | 118209   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.8e+03  |\n","|    ep_rew_mean      | 356      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2820     |\n","|    fps              | 266      |\n","|    time_elapsed     | 2150     |\n","|    total_timesteps  | 573719   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.021    |\n","|    n_updates        | 118429   |\n","----------------------------------\n","Eval num_timesteps=575000, episode_reward=353.00 +/- 75.47\n","Episode length: 2859.60 +/- 200.47\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 2.86e+03 |\n","|    mean_reward      | 353      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 575000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0427   |\n","|    n_updates        | 118749   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.81e+03 |\n","|    ep_rew_mean      | 358      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2824     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2163     |\n","|    total_timesteps  | 575147   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0175   |\n","|    n_updates        | 118786   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.81e+03 |\n","|    ep_rew_mean      | 360      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2828     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2166     |\n","|    total_timesteps  | 575753   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0488   |\n","|    n_updates        | 118938   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.81e+03 |\n","|    ep_rew_mean      | 361      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2832     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2169     |\n","|    total_timesteps  | 576845   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0251   |\n","|    n_updates        | 119211   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.8e+03  |\n","|    ep_rew_mean      | 360      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2836     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2172     |\n","|    total_timesteps  | 577661   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0174   |\n","|    n_updates        | 119415   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.8e+03  |\n","|    ep_rew_mean      | 358      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2840     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2177     |\n","|    total_timesteps  | 578623   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00788  |\n","|    n_updates        | 119655   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.8e+03  |\n","|    ep_rew_mean      | 357      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2844     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2180     |\n","|    total_timesteps  | 579477   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0464   |\n","|    n_updates        | 119869   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.8e+03  |\n","|    ep_rew_mean      | 357      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2848     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2182     |\n","|    total_timesteps  | 580098   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0348   |\n","|    n_updates        | 120024   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.8e+03  |\n","|    ep_rew_mean      | 355      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2852     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2186     |\n","|    total_timesteps  | 581106   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0213   |\n","|    n_updates        | 120276   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.82e+03 |\n","|    ep_rew_mean      | 352      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2856     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2190     |\n","|    total_timesteps  | 582052   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0248   |\n","|    n_updates        | 120512   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.8e+03  |\n","|    ep_rew_mean      | 350      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2860     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2193     |\n","|    total_timesteps  | 582822   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0325   |\n","|    n_updates        | 120705   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.81e+03 |\n","|    ep_rew_mean      | 352      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2864     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2198     |\n","|    total_timesteps  | 583953   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0245   |\n","|    n_updates        | 120988   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.8e+03  |\n","|    ep_rew_mean      | 350      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2868     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2203     |\n","|    total_timesteps  | 585085   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0356   |\n","|    n_updates        | 121271   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.81e+03 |\n","|    ep_rew_mean      | 351      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2872     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2206     |\n","|    total_timesteps  | 585871   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0383   |\n","|    n_updates        | 121467   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.82e+03 |\n","|    ep_rew_mean      | 353      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2876     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2210     |\n","|    total_timesteps  | 586787   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0185   |\n","|    n_updates        | 121696   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.81e+03 |\n","|    ep_rew_mean      | 352      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2880     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2213     |\n","|    total_timesteps  | 587601   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0189   |\n","|    n_updates        | 121900   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.81e+03 |\n","|    ep_rew_mean      | 350      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2884     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2217     |\n","|    total_timesteps  | 588599   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0138   |\n","|    n_updates        | 122149   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.82e+03 |\n","|    ep_rew_mean      | 352      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2888     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2222     |\n","|    total_timesteps  | 589795   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0264   |\n","|    n_updates        | 122448   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.83e+03 |\n","|    ep_rew_mean      | 354      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2892     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2227     |\n","|    total_timesteps  | 591075   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0219   |\n","|    n_updates        | 122768   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.84e+03 |\n","|    ep_rew_mean      | 355      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2896     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2231     |\n","|    total_timesteps  | 592043   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0315   |\n","|    n_updates        | 123010   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.85e+03 |\n","|    ep_rew_mean      | 358      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2900     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2237     |\n","|    total_timesteps  | 593679   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0104   |\n","|    n_updates        | 123419   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.86e+03 |\n","|    ep_rew_mean      | 360      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2904     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2241     |\n","|    total_timesteps  | 594620   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0237   |\n","|    n_updates        | 123654   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.85e+03 |\n","|    ep_rew_mean      | 356      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2908     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2246     |\n","|    total_timesteps  | 595733   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0219   |\n","|    n_updates        | 123933   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.86e+03 |\n","|    ep_rew_mean      | 356      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2912     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2250     |\n","|    total_timesteps  | 596666   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0424   |\n","|    n_updates        | 124166   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.86e+03 |\n","|    ep_rew_mean      | 356      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2916     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2254     |\n","|    total_timesteps  | 597749   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0155   |\n","|    n_updates        | 124437   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.85e+03 |\n","|    ep_rew_mean      | 353      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2920     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2255     |\n","|    total_timesteps  | 598214   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0309   |\n","|    n_updates        | 124553   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.87e+03 |\n","|    ep_rew_mean      | 356      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2924     |\n","|    fps              | 265      |\n","|    time_elapsed     | 2261     |\n","|    total_timesteps  | 599597   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0647   |\n","|    n_updates        | 124899   |\n","----------------------------------\n","Eval num_timesteps=600000, episode_reward=412.00 +/- 158.20\n","Episode length: 3269.80 +/- 937.68\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 3.27e+03 |\n","|    mean_reward      | 412      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 600000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0574   |\n","|    n_updates        | 124999   |\n","----------------------------------\n","New best mean reward!\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.84e+03 |\n","|    ep_rew_mean      | 355      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2928     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2277     |\n","|    total_timesteps  | 600998   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0253   |\n","|    n_updates        | 125249   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.84e+03 |\n","|    ep_rew_mean      | 354      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2932     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2282     |\n","|    total_timesteps  | 602398   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0166   |\n","|    n_updates        | 125599   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.86e+03 |\n","|    ep_rew_mean      | 357      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2936     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2287     |\n","|    total_timesteps  | 603422   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.038    |\n","|    n_updates        | 125855   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.89e+03 |\n","|    ep_rew_mean      | 363      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2940     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2292     |\n","|    total_timesteps  | 604989   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0272   |\n","|    n_updates        | 126247   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.91e+03 |\n","|    ep_rew_mean      | 366      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2944     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2296     |\n","|    total_timesteps  | 605938   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0215   |\n","|    n_updates        | 126484   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.93e+03 |\n","|    ep_rew_mean      | 371      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2948     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2304     |\n","|    total_timesteps  | 607846   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0257   |\n","|    n_updates        | 126961   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.93e+03 |\n","|    ep_rew_mean      | 372      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2952     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2307     |\n","|    total_timesteps  | 608874   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0383   |\n","|    n_updates        | 127218   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.93e+03 |\n","|    ep_rew_mean      | 375      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2956     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2313     |\n","|    total_timesteps  | 610321   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0149   |\n","|    n_updates        | 127580   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.93e+03 |\n","|    ep_rew_mean      | 375      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2960     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2318     |\n","|    total_timesteps  | 611554   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0131   |\n","|    n_updates        | 127888   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.93e+03 |\n","|    ep_rew_mean      | 375      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2964     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2324     |\n","|    total_timesteps  | 613190   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0274   |\n","|    n_updates        | 128297   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.95e+03 |\n","|    ep_rew_mean      | 380      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2968     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2331     |\n","|    total_timesteps  | 614907   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.101    |\n","|    n_updates        | 128726   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.97e+03 |\n","|    ep_rew_mean      | 379      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2972     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2337     |\n","|    total_timesteps  | 616420   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0229   |\n","|    n_updates        | 129104   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.97e+03 |\n","|    ep_rew_mean      | 379      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2976     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2341     |\n","|    total_timesteps  | 617250   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0192   |\n","|    n_updates        | 129312   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.97e+03 |\n","|    ep_rew_mean      | 379      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2980     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2344     |\n","|    total_timesteps  | 618098   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0288   |\n","|    n_updates        | 129524   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.97e+03 |\n","|    ep_rew_mean      | 378      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2984     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2348     |\n","|    total_timesteps  | 619048   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0417   |\n","|    n_updates        | 129761   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.99e+03 |\n","|    ep_rew_mean      | 380      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2988     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2353     |\n","|    total_timesteps  | 620259   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.037    |\n","|    n_updates        | 130064   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.99e+03 |\n","|    ep_rew_mean      | 380      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2992     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2357     |\n","|    total_timesteps  | 621127   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0251   |\n","|    n_updates        | 130281   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.98e+03 |\n","|    ep_rew_mean      | 380      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 2996     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2361     |\n","|    total_timesteps  | 622277   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0373   |\n","|    n_updates        | 130569   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.99e+03 |\n","|    ep_rew_mean      | 384      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3000     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2364     |\n","|    total_timesteps  | 623110   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0235   |\n","|    n_updates        | 130777   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 2.98e+03 |\n","|    ep_rew_mean      | 384      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3004     |\n","|    fps              | 263      |\n","|    time_elapsed     | 2369     |\n","|    total_timesteps  | 624160   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0329   |\n","|    n_updates        | 131039   |\n","----------------------------------\n","Eval num_timesteps=625000, episode_reward=407.00 +/- 206.39\n","Episode length: 3921.80 +/- 1261.58\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 3.92e+03 |\n","|    mean_reward      | 407      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 625000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0337   |\n","|    n_updates        | 131249   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3e+03    |\n","|    ep_rew_mean      | 389      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3008     |\n","|    fps              | 262      |\n","|    time_elapsed     | 2384     |\n","|    total_timesteps  | 625085   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0475   |\n","|    n_updates        | 131271   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.03e+03 |\n","|    ep_rew_mean      | 394      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3012     |\n","|    fps              | 262      |\n","|    time_elapsed     | 2389     |\n","|    total_timesteps  | 626524   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0185   |\n","|    n_updates        | 131630   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.04e+03 |\n","|    ep_rew_mean      | 393      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3016     |\n","|    fps              | 262      |\n","|    time_elapsed     | 2395     |\n","|    total_timesteps  | 627927   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.02     |\n","|    n_updates        | 131981   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.04e+03 |\n","|    ep_rew_mean      | 396      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3020     |\n","|    fps              | 262      |\n","|    time_elapsed     | 2400     |\n","|    total_timesteps  | 629152   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0559   |\n","|    n_updates        | 132287   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.06e+03 |\n","|    ep_rew_mean      | 399      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3024     |\n","|    fps              | 261      |\n","|    time_elapsed     | 2410     |\n","|    total_timesteps  | 631600   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0204   |\n","|    n_updates        | 132899   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.07e+03 |\n","|    ep_rew_mean      | 399      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3028     |\n","|    fps              | 262      |\n","|    time_elapsed     | 2413     |\n","|    total_timesteps  | 632377   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0321   |\n","|    n_updates        | 133094   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.06e+03 |\n","|    ep_rew_mean      | 406      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3032     |\n","|    fps              | 262      |\n","|    time_elapsed     | 2419     |\n","|    total_timesteps  | 633918   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0363   |\n","|    n_updates        | 133479   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.06e+03 |\n","|    ep_rew_mean      | 406      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3036     |\n","|    fps              | 261      |\n","|    time_elapsed     | 2423     |\n","|    total_timesteps  | 634900   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0532   |\n","|    n_updates        | 133724   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.06e+03 |\n","|    ep_rew_mean      | 406      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3040     |\n","|    fps              | 261      |\n","|    time_elapsed     | 2427     |\n","|    total_timesteps  | 635925   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0171   |\n","|    n_updates        | 133981   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.07e+03 |\n","|    ep_rew_mean      | 410      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3044     |\n","|    fps              | 261      |\n","|    time_elapsed     | 2433     |\n","|    total_timesteps  | 637366   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0424   |\n","|    n_updates        | 134341   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.05e+03 |\n","|    ep_rew_mean      | 405      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3048     |\n","|    fps              | 261      |\n","|    time_elapsed     | 2436     |\n","|    total_timesteps  | 637992   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0299   |\n","|    n_updates        | 134497   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.05e+03 |\n","|    ep_rew_mean      | 403      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3052     |\n","|    fps              | 261      |\n","|    time_elapsed     | 2440     |\n","|    total_timesteps  | 639073   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0237   |\n","|    n_updates        | 134768   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.07e+03 |\n","|    ep_rew_mean      | 411      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3056     |\n","|    fps              | 261      |\n","|    time_elapsed     | 2445     |\n","|    total_timesteps  | 640639   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0273   |\n","|    n_updates        | 135159   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.09e+03 |\n","|    ep_rew_mean      | 413      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3060     |\n","|    fps              | 261      |\n","|    time_elapsed     | 2451     |\n","|    total_timesteps  | 641972   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0328   |\n","|    n_updates        | 135492   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.1e+03  |\n","|    ep_rew_mean      | 416      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3064     |\n","|    fps              | 261      |\n","|    time_elapsed     | 2456     |\n","|    total_timesteps  | 643255   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0143   |\n","|    n_updates        | 135813   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.1e+03  |\n","|    ep_rew_mean      | 416      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3068     |\n","|    fps              | 261      |\n","|    time_elapsed     | 2462     |\n","|    total_timesteps  | 644746   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.039    |\n","|    n_updates        | 136186   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.11e+03 |\n","|    ep_rew_mean      | 419      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3072     |\n","|    fps              | 261      |\n","|    time_elapsed     | 2465     |\n","|    total_timesteps  | 645651   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0289   |\n","|    n_updates        | 136412   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.1e+03  |\n","|    ep_rew_mean      | 416      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3076     |\n","|    fps              | 261      |\n","|    time_elapsed     | 2468     |\n","|    total_timesteps  | 646429   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0261   |\n","|    n_updates        | 136607   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.09e+03 |\n","|    ep_rew_mean      | 416      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3080     |\n","|    fps              | 261      |\n","|    time_elapsed     | 2473     |\n","|    total_timesteps  | 647644   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0443   |\n","|    n_updates        | 136910   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.09e+03 |\n","|    ep_rew_mean      | 415      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3084     |\n","|    fps              | 261      |\n","|    time_elapsed     | 2478     |\n","|    total_timesteps  | 648683   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0248   |\n","|    n_updates        | 137170   |\n","----------------------------------\n","Eval num_timesteps=650000, episode_reward=482.00 +/- 178.37\n","Episode length: 2940.20 +/- 374.18\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 2.94e+03 |\n","|    mean_reward      | 482      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 650000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0993   |\n","|    n_updates        | 137499   |\n","----------------------------------\n","New best mean reward!\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.12e+03 |\n","|    ep_rew_mean      | 421      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3088     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2495     |\n","|    total_timesteps  | 650812   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0121   |\n","|    n_updates        | 137702   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.13e+03 |\n","|    ep_rew_mean      | 421      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3092     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2502     |\n","|    total_timesteps  | 652449   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0442   |\n","|    n_updates        | 138112   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.13e+03 |\n","|    ep_rew_mean      | 421      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3096     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2505     |\n","|    total_timesteps  | 653204   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0292   |\n","|    n_updates        | 138300   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.14e+03 |\n","|    ep_rew_mean      | 421      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3100     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2511     |\n","|    total_timesteps  | 654814   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0403   |\n","|    n_updates        | 138703   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.16e+03 |\n","|    ep_rew_mean      | 429      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3104     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2518     |\n","|    total_timesteps  | 656397   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0387   |\n","|    n_updates        | 139099   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.16e+03 |\n","|    ep_rew_mean      | 429      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3108     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2522     |\n","|    total_timesteps  | 657532   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0312   |\n","|    n_updates        | 139382   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.18e+03 |\n","|    ep_rew_mean      | 434      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3112     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2526     |\n","|    total_timesteps  | 658590   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0203   |\n","|    n_updates        | 139647   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.2e+03  |\n","|    ep_rew_mean      | 439      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3116     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2535     |\n","|    total_timesteps  | 660620   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0163   |\n","|    n_updates        | 140154   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.2e+03  |\n","|    ep_rew_mean      | 439      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3120     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2539     |\n","|    total_timesteps  | 661646   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0288   |\n","|    n_updates        | 140411   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.2e+03  |\n","|    ep_rew_mean      | 437      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3124     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2541     |\n","|    total_timesteps  | 662297   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.018    |\n","|    n_updates        | 140574   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.2e+03  |\n","|    ep_rew_mean      | 437      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3128     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2547     |\n","|    total_timesteps  | 663444   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0175   |\n","|    n_updates        | 140860   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.21e+03 |\n","|    ep_rew_mean      | 441      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3132     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2553     |\n","|    total_timesteps  | 665284   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.029    |\n","|    n_updates        | 141320   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.21e+03 |\n","|    ep_rew_mean      | 441      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3136     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2559     |\n","|    total_timesteps  | 666638   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0277   |\n","|    n_updates        | 141659   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.2e+03  |\n","|    ep_rew_mean      | 440      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3140     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2560     |\n","|    total_timesteps  | 666968   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.017    |\n","|    n_updates        | 141741   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.21e+03 |\n","|    ep_rew_mean      | 444      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3144     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2565     |\n","|    total_timesteps  | 668436   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0409   |\n","|    n_updates        | 142108   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.23e+03 |\n","|    ep_rew_mean      | 443      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3148     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2574     |\n","|    total_timesteps  | 670353   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0251   |\n","|    n_updates        | 142588   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.23e+03 |\n","|    ep_rew_mean      | 444      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3152     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2581     |\n","|    total_timesteps  | 672444   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0203   |\n","|    n_updates        | 143110   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.25e+03 |\n","|    ep_rew_mean      | 444      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3156     |\n","|    fps              | 260      |\n","|    time_elapsed     | 2587     |\n","|    total_timesteps  | 673785   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0403   |\n","|    n_updates        | 143446   |\n","----------------------------------\n","Eval num_timesteps=675000, episode_reward=523.00 +/- 196.76\n","Episode length: 3475.40 +/- 890.37\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 3.48e+03 |\n","|    mean_reward      | 523      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 675000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0256   |\n","|    n_updates        | 143749   |\n","----------------------------------\n","New best mean reward!\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.26e+03 |\n","|    ep_rew_mean      | 445      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3160     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2603     |\n","|    total_timesteps  | 675039   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0161   |\n","|    n_updates        | 143759   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.26e+03 |\n","|    ep_rew_mean      | 446      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3164     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2607     |\n","|    total_timesteps  | 676294   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0497   |\n","|    n_updates        | 144073   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.27e+03 |\n","|    ep_rew_mean      | 449      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3168     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2614     |\n","|    total_timesteps  | 677958   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0459   |\n","|    n_updates        | 144489   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.29e+03 |\n","|    ep_rew_mean      | 454      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3172     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2618     |\n","|    total_timesteps  | 679071   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0161   |\n","|    n_updates        | 144767   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.31e+03 |\n","|    ep_rew_mean      | 458      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3176     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2623     |\n","|    total_timesteps  | 680408   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0459   |\n","|    n_updates        | 145101   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.29e+03 |\n","|    ep_rew_mean      | 453      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3180     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2630     |\n","|    total_timesteps  | 681791   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0153   |\n","|    n_updates        | 145447   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.3e+03  |\n","|    ep_rew_mean      | 450      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3184     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2632     |\n","|    total_timesteps  | 682349   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0561   |\n","|    n_updates        | 145587   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.29e+03 |\n","|    ep_rew_mean      | 449      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3188     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2639     |\n","|    total_timesteps  | 684172   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0319   |\n","|    n_updates        | 146042   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.28e+03 |\n","|    ep_rew_mean      | 447      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3192     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2644     |\n","|    total_timesteps  | 685360   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0174   |\n","|    n_updates        | 146339   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.28e+03 |\n","|    ep_rew_mean      | 444      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3196     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2647     |\n","|    total_timesteps  | 686296   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0205   |\n","|    n_updates        | 146573   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.27e+03 |\n","|    ep_rew_mean      | 443      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3200     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2653     |\n","|    total_timesteps  | 687799   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0322   |\n","|    n_updates        | 146949   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.28e+03 |\n","|    ep_rew_mean      | 446      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3204     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2659     |\n","|    total_timesteps  | 689482   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0131   |\n","|    n_updates        | 147370   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.28e+03 |\n","|    ep_rew_mean      | 447      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3208     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2663     |\n","|    total_timesteps  | 690533   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0306   |\n","|    n_updates        | 147633   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.29e+03 |\n","|    ep_rew_mean      | 446      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3212     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2669     |\n","|    total_timesteps  | 691834   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0317   |\n","|    n_updates        | 147958   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.29e+03 |\n","|    ep_rew_mean      | 445      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3216     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2673     |\n","|    total_timesteps  | 692889   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0185   |\n","|    n_updates        | 148222   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.28e+03 |\n","|    ep_rew_mean      | 444      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3220     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2676     |\n","|    total_timesteps  | 693955   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0422   |\n","|    n_updates        | 148488   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.3e+03  |\n","|    ep_rew_mean      | 449      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3224     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2681     |\n","|    total_timesteps  | 695095   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0204   |\n","|    n_updates        | 148773   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.27e+03 |\n","|    ep_rew_mean      | 446      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3228     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2687     |\n","|    total_timesteps  | 696761   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0165   |\n","|    n_updates        | 149190   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.26e+03 |\n","|    ep_rew_mean      | 444      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3232     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2691     |\n","|    total_timesteps  | 697824   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0307   |\n","|    n_updates        | 149455   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.26e+03 |\n","|    ep_rew_mean      | 443      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3236     |\n","|    fps              | 259      |\n","|    time_elapsed     | 2697     |\n","|    total_timesteps  | 699275   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0367   |\n","|    n_updates        | 149818   |\n","----------------------------------\n","Eval num_timesteps=700000, episode_reward=773.00 +/- 322.65\n","Episode length: 4566.60 +/- 1537.02\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 4.57e+03 |\n","|    mean_reward      | 773      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 700000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0397   |\n","|    n_updates        | 149999   |\n","----------------------------------\n","New best mean reward!\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.29e+03 |\n","|    ep_rew_mean      | 449      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3240     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2714     |\n","|    total_timesteps  | 700458   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0624   |\n","|    n_updates        | 150114   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.3e+03  |\n","|    ep_rew_mean      | 453      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3244     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2719     |\n","|    total_timesteps  | 701746   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0107   |\n","|    n_updates        | 150436   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.32e+03 |\n","|    ep_rew_mean      | 457      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3248     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2724     |\n","|    total_timesteps  | 703014   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0247   |\n","|    n_updates        | 150753   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.34e+03 |\n","|    ep_rew_mean      | 459      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3252     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2730     |\n","|    total_timesteps  | 704760   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00649  |\n","|    n_updates        | 151189   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.34e+03 |\n","|    ep_rew_mean      | 457      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3256     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2733     |\n","|    total_timesteps  | 705530   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0144   |\n","|    n_updates        | 151382   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.37e+03 |\n","|    ep_rew_mean      | 461      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3260     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2742     |\n","|    total_timesteps  | 707741   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0313   |\n","|    n_updates        | 151935   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.37e+03 |\n","|    ep_rew_mean      | 460      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3264     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2746     |\n","|    total_timesteps  | 708900   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0249   |\n","|    n_updates        | 152224   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.38e+03 |\n","|    ep_rew_mean      | 462      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3268     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2753     |\n","|    total_timesteps  | 710727   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0154   |\n","|    n_updates        | 152681   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.38e+03 |\n","|    ep_rew_mean      | 464      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3272     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2756     |\n","|    total_timesteps  | 711599   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0382   |\n","|    n_updates        | 152899   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.37e+03 |\n","|    ep_rew_mean      | 465      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3276     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2763     |\n","|    total_timesteps  | 713092   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0271   |\n","|    n_updates        | 153272   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.38e+03 |\n","|    ep_rew_mean      | 467      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3280     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2768     |\n","|    total_timesteps  | 714574   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0231   |\n","|    n_updates        | 153643   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.39e+03 |\n","|    ep_rew_mean      | 469      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3284     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2772     |\n","|    total_timesteps  | 715840   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0375   |\n","|    n_updates        | 153959   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.42e+03 |\n","|    ep_rew_mean      | 471      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3288     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2779     |\n","|    total_timesteps  | 717432   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.037    |\n","|    n_updates        | 154357   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.41e+03 |\n","|    ep_rew_mean      | 468      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3292     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2782     |\n","|    total_timesteps  | 718426   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0243   |\n","|    n_updates        | 154606   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.48e+03 |\n","|    ep_rew_mean      | 476      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3296     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2792     |\n","|    total_timesteps  | 720891   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.01     |\n","|    n_updates        | 155222   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.48e+03 |\n","|    ep_rew_mean      | 476      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3300     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2795     |\n","|    total_timesteps  | 721823   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0351   |\n","|    n_updates        | 155455   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.46e+03 |\n","|    ep_rew_mean      | 473      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3304     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2800     |\n","|    total_timesteps  | 723106   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0182   |\n","|    n_updates        | 155776   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.5e+03  |\n","|    ep_rew_mean      | 480      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3308     |\n","|    fps              | 258      |\n","|    time_elapsed     | 2805     |\n","|    total_timesteps  | 724332   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.02     |\n","|    n_updates        | 156082   |\n","----------------------------------\n","Eval num_timesteps=725000, episode_reward=439.00 +/- 214.49\n","Episode length: 4321.80 +/- 1100.50\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 4.32e+03 |\n","|    mean_reward      | 439      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 725000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0287   |\n","|    n_updates        | 156249   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.49e+03 |\n","|    ep_rew_mean      | 484      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3312     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2823     |\n","|    total_timesteps  | 725900   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0146   |\n","|    n_updates        | 156474   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.48e+03 |\n","|    ep_rew_mean      | 482      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3316     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2831     |\n","|    total_timesteps  | 727793   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.044    |\n","|    n_updates        | 156948   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.5e+03  |\n","|    ep_rew_mean      | 486      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3320     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2836     |\n","|    total_timesteps  | 729207   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0423   |\n","|    n_updates        | 157301   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.49e+03 |\n","|    ep_rew_mean      | 484      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3324     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2840     |\n","|    total_timesteps  | 730472   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00942  |\n","|    n_updates        | 157617   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.51e+03 |\n","|    ep_rew_mean      | 486      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3328     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2848     |\n","|    total_timesteps  | 732317   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00842  |\n","|    n_updates        | 158079   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.52e+03 |\n","|    ep_rew_mean      | 487      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3332     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2850     |\n","|    total_timesteps  | 732942   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0204   |\n","|    n_updates        | 158235   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.54e+03 |\n","|    ep_rew_mean      | 492      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3336     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2855     |\n","|    total_timesteps  | 734335   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0276   |\n","|    n_updates        | 158583   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.55e+03 |\n","|    ep_rew_mean      | 494      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3340     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2862     |\n","|    total_timesteps  | 736080   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0504   |\n","|    n_updates        | 159019   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.57e+03 |\n","|    ep_rew_mean      | 500      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3344     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2867     |\n","|    total_timesteps  | 737592   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0304   |\n","|    n_updates        | 159397   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.57e+03 |\n","|    ep_rew_mean      | 498      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3348     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2874     |\n","|    total_timesteps  | 739250   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0121   |\n","|    n_updates        | 159812   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.57e+03 |\n","|    ep_rew_mean      | 498      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3352     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2877     |\n","|    total_timesteps  | 740171   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0151   |\n","|    n_updates        | 160042   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.56e+03 |\n","|    ep_rew_mean      | 496      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3356     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2880     |\n","|    total_timesteps  | 741029   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.018    |\n","|    n_updates        | 160257   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.57e+03 |\n","|    ep_rew_mean      | 499      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3360     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2889     |\n","|    total_timesteps  | 743182   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0215   |\n","|    n_updates        | 160795   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.59e+03 |\n","|    ep_rew_mean      | 500      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3364     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2892     |\n","|    total_timesteps  | 744253   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0363   |\n","|    n_updates        | 161063   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.6e+03  |\n","|    ep_rew_mean      | 502      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3368     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2902     |\n","|    total_timesteps  | 746613   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0227   |\n","|    n_updates        | 161653   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.66e+03 |\n","|    ep_rew_mean      | 510      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3372     |\n","|    fps              | 257      |\n","|    time_elapsed     | 2908     |\n","|    total_timesteps  | 748358   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0244   |\n","|    n_updates        | 162089   |\n","----------------------------------\n","Eval num_timesteps=750000, episode_reward=706.00 +/- 179.62\n","Episode length: 4547.60 +/- 988.71\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 4.55e+03 |\n","|    mean_reward      | 706      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 750000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0362   |\n","|    n_updates        | 162499   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.67e+03 |\n","|    ep_rew_mean      | 512      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3376     |\n","|    fps              | 256      |\n","|    time_elapsed     | 2930     |\n","|    total_timesteps  | 750406   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0361   |\n","|    n_updates        | 162601   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.67e+03 |\n","|    ep_rew_mean      | 511      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3380     |\n","|    fps              | 256      |\n","|    time_elapsed     | 2936     |\n","|    total_timesteps  | 751974   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0244   |\n","|    n_updates        | 162993   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.69e+03 |\n","|    ep_rew_mean      | 515      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3384     |\n","|    fps              | 256      |\n","|    time_elapsed     | 2943     |\n","|    total_timesteps  | 753812   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0385   |\n","|    n_updates        | 163452   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.71e+03 |\n","|    ep_rew_mean      | 519      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3388     |\n","|    fps              | 256      |\n","|    time_elapsed     | 2949     |\n","|    total_timesteps  | 755487   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.023    |\n","|    n_updates        | 163871   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.69e+03 |\n","|    ep_rew_mean      | 514      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3392     |\n","|    fps              | 256      |\n","|    time_elapsed     | 2954     |\n","|    total_timesteps  | 756572   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0594   |\n","|    n_updates        | 164142   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.72e+03 |\n","|    ep_rew_mean      | 517      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3396     |\n","|    fps              | 256      |\n","|    time_elapsed     | 2960     |\n","|    total_timesteps  | 758371   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0276   |\n","|    n_updates        | 164592   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.74e+03 |\n","|    ep_rew_mean      | 518      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3400     |\n","|    fps              | 256      |\n","|    time_elapsed     | 2966     |\n","|    total_timesteps  | 759914   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.021    |\n","|    n_updates        | 164978   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.76e+03 |\n","|    ep_rew_mean      | 522      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3404     |\n","|    fps              | 256      |\n","|    time_elapsed     | 2969     |\n","|    total_timesteps  | 760799   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0204   |\n","|    n_updates        | 165199   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.75e+03 |\n","|    ep_rew_mean      | 524      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3408     |\n","|    fps              | 256      |\n","|    time_elapsed     | 2978     |\n","|    total_timesteps  | 763013   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0848   |\n","|    n_updates        | 165753   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.75e+03 |\n","|    ep_rew_mean      | 523      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3412     |\n","|    fps              | 256      |\n","|    time_elapsed     | 2983     |\n","|    total_timesteps  | 764365   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0147   |\n","|    n_updates        | 166091   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.76e+03 |\n","|    ep_rew_mean      | 523      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3416     |\n","|    fps              | 256      |\n","|    time_elapsed     | 2987     |\n","|    total_timesteps  | 765552   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.016    |\n","|    n_updates        | 166387   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.76e+03 |\n","|    ep_rew_mean      | 525      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3420     |\n","|    fps              | 256      |\n","|    time_elapsed     | 2996     |\n","|    total_timesteps  | 767918   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0338   |\n","|    n_updates        | 166979   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.79e+03 |\n","|    ep_rew_mean      | 536      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3424     |\n","|    fps              | 256      |\n","|    time_elapsed     | 3000     |\n","|    total_timesteps  | 769103   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0345   |\n","|    n_updates        | 167275   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.78e+03 |\n","|    ep_rew_mean      | 535      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3428     |\n","|    fps              | 256      |\n","|    time_elapsed     | 3005     |\n","|    total_timesteps  | 770205   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0217   |\n","|    n_updates        | 167551   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.76e+03 |\n","|    ep_rew_mean      | 531      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3432     |\n","|    fps              | 256      |\n","|    time_elapsed     | 3010     |\n","|    total_timesteps  | 771449   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.035    |\n","|    n_updates        | 167862   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.76e+03 |\n","|    ep_rew_mean      | 531      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3436     |\n","|    fps              | 256      |\n","|    time_elapsed     | 3017     |\n","|    total_timesteps  | 773203   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0816   |\n","|    n_updates        | 168300   |\n","----------------------------------\n","Eval num_timesteps=775000, episode_reward=650.00 +/- 94.07\n","Episode length: 3875.20 +/- 320.99\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 3.88e+03 |\n","|    mean_reward      | 650      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 775000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.023    |\n","|    n_updates        | 168749   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.77e+03 |\n","|    ep_rew_mean      | 535      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3440     |\n","|    fps              | 255      |\n","|    time_elapsed     | 3038     |\n","|    total_timesteps  | 776106   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0577   |\n","|    n_updates        | 169026   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.81e+03 |\n","|    ep_rew_mean      | 541      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3444     |\n","|    fps              | 255      |\n","|    time_elapsed     | 3042     |\n","|    total_timesteps  | 777158   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00939  |\n","|    n_updates        | 169289   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.82e+03 |\n","|    ep_rew_mean      | 546      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3448     |\n","|    fps              | 255      |\n","|    time_elapsed     | 3050     |\n","|    total_timesteps  | 779201   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.029    |\n","|    n_updates        | 169800   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.83e+03 |\n","|    ep_rew_mean      | 548      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3452     |\n","|    fps              | 255      |\n","|    time_elapsed     | 3059     |\n","|    total_timesteps  | 781537   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0143   |\n","|    n_updates        | 170384   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.83e+03 |\n","|    ep_rew_mean      | 548      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3456     |\n","|    fps              | 255      |\n","|    time_elapsed     | 3064     |\n","|    total_timesteps  | 782795   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0376   |\n","|    n_updates        | 170698   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.85e+03 |\n","|    ep_rew_mean      | 550      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3460     |\n","|    fps              | 255      |\n","|    time_elapsed     | 3067     |\n","|    total_timesteps  | 783743   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0247   |\n","|    n_updates        | 170935   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.83e+03 |\n","|    ep_rew_mean      | 545      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3464     |\n","|    fps              | 255      |\n","|    time_elapsed     | 3072     |\n","|    total_timesteps  | 784953   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00685  |\n","|    n_updates        | 171238   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.83e+03 |\n","|    ep_rew_mean      | 547      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3468     |\n","|    fps              | 255      |\n","|    time_elapsed     | 3078     |\n","|    total_timesteps  | 786549   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0114   |\n","|    n_updates        | 171637   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.85e+03 |\n","|    ep_rew_mean      | 551      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3472     |\n","|    fps              | 255      |\n","|    time_elapsed     | 3084     |\n","|    total_timesteps  | 788066   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0157   |\n","|    n_updates        | 172016   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.87e+03 |\n","|    ep_rew_mean      | 551      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3476     |\n","|    fps              | 255      |\n","|    time_elapsed     | 3094     |\n","|    total_timesteps  | 790945   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.017    |\n","|    n_updates        | 172736   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.87e+03 |\n","|    ep_rew_mean      | 548      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3480     |\n","|    fps              | 255      |\n","|    time_elapsed     | 3100     |\n","|    total_timesteps  | 792315   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0191   |\n","|    n_updates        | 173078   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.89e+03 |\n","|    ep_rew_mean      | 552      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3484     |\n","|    fps              | 255      |\n","|    time_elapsed     | 3107     |\n","|    total_timesteps  | 794255   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0234   |\n","|    n_updates        | 173563   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.92e+03 |\n","|    ep_rew_mean      | 559      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3488     |\n","|    fps              | 255      |\n","|    time_elapsed     | 3112     |\n","|    total_timesteps  | 795337   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0197   |\n","|    n_updates        | 173834   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.93e+03 |\n","|    ep_rew_mean      | 563      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3492     |\n","|    fps              | 255      |\n","|    time_elapsed     | 3118     |\n","|    total_timesteps  | 797087   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.023    |\n","|    n_updates        | 174271   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.93e+03 |\n","|    ep_rew_mean      | 563      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3496     |\n","|    fps              | 255      |\n","|    time_elapsed     | 3125     |\n","|    total_timesteps  | 798730   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0159   |\n","|    n_updates        | 174682   |\n","----------------------------------\n","Eval num_timesteps=800000, episode_reward=571.00 +/- 278.07\n","Episode length: 4404.00 +/- 1842.82\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 4.4e+03  |\n","|    mean_reward      | 571      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 800000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0215   |\n","|    n_updates        | 174999   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.94e+03 |\n","|    ep_rew_mean      | 561      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3500     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3143     |\n","|    total_timesteps  | 800229   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0161   |\n","|    n_updates        | 175057   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.93e+03 |\n","|    ep_rew_mean      | 561      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3504     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3148     |\n","|    total_timesteps  | 801795   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0257   |\n","|    n_updates        | 175448   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.96e+03 |\n","|    ep_rew_mean      | 564      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3508     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3155     |\n","|    total_timesteps  | 803487   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0168   |\n","|    n_updates        | 175871   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.94e+03 |\n","|    ep_rew_mean      | 563      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3512     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3160     |\n","|    total_timesteps  | 804780   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0234   |\n","|    n_updates        | 176194   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.93e+03 |\n","|    ep_rew_mean      | 564      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3516     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3165     |\n","|    total_timesteps  | 806097   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0249   |\n","|    n_updates        | 176524   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.94e+03 |\n","|    ep_rew_mean      | 565      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3520     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3172     |\n","|    total_timesteps  | 808116   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0134   |\n","|    n_updates        | 177028   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.97e+03 |\n","|    ep_rew_mean      | 568      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3524     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3179     |\n","|    total_timesteps  | 809827   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00805  |\n","|    n_updates        | 177456   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4e+03    |\n","|    ep_rew_mean      | 569      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3528     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3190     |\n","|    total_timesteps  | 812698   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0111   |\n","|    n_updates        | 178174   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.01e+03 |\n","|    ep_rew_mean      | 569      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3532     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3194     |\n","|    total_timesteps  | 813750   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0193   |\n","|    n_updates        | 178437   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4e+03    |\n","|    ep_rew_mean      | 571      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3536     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3200     |\n","|    total_timesteps  | 815550   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0301   |\n","|    n_updates        | 178887   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.01e+03 |\n","|    ep_rew_mean      | 571      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3540     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3206     |\n","|    total_timesteps  | 816703   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0452   |\n","|    n_updates        | 179175   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.02e+03 |\n","|    ep_rew_mean      | 571      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3544     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3212     |\n","|    total_timesteps  | 818214   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0343   |\n","|    n_updates        | 179553   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.02e+03 |\n","|    ep_rew_mean      | 572      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3548     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3217     |\n","|    total_timesteps  | 819716   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0182   |\n","|    n_updates        | 179928   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.01e+03 |\n","|    ep_rew_mean      | 573      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3552     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3222     |\n","|    total_timesteps  | 820970   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0358   |\n","|    n_updates        | 180242   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.02e+03 |\n","|    ep_rew_mean      | 577      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3556     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3227     |\n","|    total_timesteps  | 822321   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0605   |\n","|    n_updates        | 180580   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.02e+03 |\n","|    ep_rew_mean      | 576      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3560     |\n","|    fps              | 254      |\n","|    time_elapsed     | 3234     |\n","|    total_timesteps  | 823914   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.017    |\n","|    n_updates        | 180978   |\n","----------------------------------\n","Eval num_timesteps=825000, episode_reward=694.00 +/- 379.49\n","Episode length: 4759.60 +/- 2298.86\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 4.76e+03 |\n","|    mean_reward      | 694      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 825000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0172   |\n","|    n_updates        | 181249   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.04e+03 |\n","|    ep_rew_mean      | 574      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3564     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3254     |\n","|    total_timesteps  | 825807   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00992  |\n","|    n_updates        | 181451   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.04e+03 |\n","|    ep_rew_mean      | 571      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3568     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3258     |\n","|    total_timesteps  | 826798   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0183   |\n","|    n_updates        | 181699   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.06e+03 |\n","|    ep_rew_mean      | 577      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3572     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3268     |\n","|    total_timesteps  | 829355   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.024    |\n","|    n_updates        | 182338   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.07e+03 |\n","|    ep_rew_mean      | 581      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3576     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3275     |\n","|    total_timesteps  | 831206   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0294   |\n","|    n_updates        | 182801   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.06e+03 |\n","|    ep_rew_mean      | 580      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3580     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3279     |\n","|    total_timesteps  | 832257   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0168   |\n","|    n_updates        | 183064   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.11e+03 |\n","|    ep_rew_mean      | 584      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3584     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3290     |\n","|    total_timesteps  | 835013   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0268   |\n","|    n_updates        | 183753   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.11e+03 |\n","|    ep_rew_mean      | 583      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3588     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3294     |\n","|    total_timesteps  | 836292   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.018    |\n","|    n_updates        | 184072   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.09e+03 |\n","|    ep_rew_mean      | 579      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3592     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3300     |\n","|    total_timesteps  | 837762   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0242   |\n","|    n_updates        | 184440   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.07e+03 |\n","|    ep_rew_mean      | 576      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3596     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3305     |\n","|    total_timesteps  | 839120   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00765  |\n","|    n_updates        | 184779   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.06e+03 |\n","|    ep_rew_mean      | 576      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3600     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3309     |\n","|    total_timesteps  | 840246   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0239   |\n","|    n_updates        | 185061   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.07e+03 |\n","|    ep_rew_mean      | 582      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3604     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3314     |\n","|    total_timesteps  | 841413   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0186   |\n","|    n_updates        | 185353   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.09e+03 |\n","|    ep_rew_mean      | 582      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3608     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3325     |\n","|    total_timesteps  | 844242   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00895  |\n","|    n_updates        | 186060   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.09e+03 |\n","|    ep_rew_mean      | 582      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3612     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3329     |\n","|    total_timesteps  | 845264   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00623  |\n","|    n_updates        | 186315   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.1e+03  |\n","|    ep_rew_mean      | 584      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3616     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3335     |\n","|    total_timesteps  | 847017   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0273   |\n","|    n_updates        | 186754   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.06e+03 |\n","|    ep_rew_mean      | 578      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3620     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3341     |\n","|    total_timesteps  | 848263   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0347   |\n","|    n_updates        | 187065   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.03e+03 |\n","|    ep_rew_mean      | 575      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3624     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3345     |\n","|    total_timesteps  | 849330   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0354   |\n","|    n_updates        | 187332   |\n","----------------------------------\n","Eval num_timesteps=850000, episode_reward=583.00 +/- 144.24\n","Episode length: 4227.00 +/- 941.90\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 4.23e+03 |\n","|    mean_reward      | 583      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 850000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0334   |\n","|    n_updates        | 187499   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.12e+03 |\n","|    ep_rew_mean      | 590      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3628     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3369     |\n","|    total_timesteps  | 852666   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0259   |\n","|    n_updates        | 188166   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.1e+03  |\n","|    ep_rew_mean      | 587      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3632     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3373     |\n","|    total_timesteps  | 853790   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0266   |\n","|    n_updates        | 188447   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.15e+03 |\n","|    ep_rew_mean      | 596      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3636     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3382     |\n","|    total_timesteps  | 855998   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0189   |\n","|    n_updates        | 188999   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.16e+03 |\n","|    ep_rew_mean      | 595      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3640     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3387     |\n","|    total_timesteps  | 857371   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00453  |\n","|    n_updates        | 189342   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.15e+03 |\n","|    ep_rew_mean      | 592      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3644     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3393     |\n","|    total_timesteps  | 858942   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0215   |\n","|    n_updates        | 189735   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.2e+03  |\n","|    ep_rew_mean      | 597      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3648     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3399     |\n","|    total_timesteps  | 860502   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.041    |\n","|    n_updates        | 190125   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.18e+03 |\n","|    ep_rew_mean      | 597      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3652     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3406     |\n","|    total_timesteps  | 862472   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0133   |\n","|    n_updates        | 190617   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.19e+03 |\n","|    ep_rew_mean      | 598      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3656     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3413     |\n","|    total_timesteps  | 864310   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0141   |\n","|    n_updates        | 191077   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.19e+03 |\n","|    ep_rew_mean      | 598      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3660     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3419     |\n","|    total_timesteps  | 865917   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00926  |\n","|    n_updates        | 191479   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.22e+03 |\n","|    ep_rew_mean      | 601      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3664     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3429     |\n","|    total_timesteps  | 868398   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0504   |\n","|    n_updates        | 192099   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.2e+03  |\n","|    ep_rew_mean      | 599      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3668     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3435     |\n","|    total_timesteps  | 870033   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0113   |\n","|    n_updates        | 192508   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.2e+03  |\n","|    ep_rew_mean      | 597      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3672     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3442     |\n","|    total_timesteps  | 871928   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0199   |\n","|    n_updates        | 192981   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.2e+03  |\n","|    ep_rew_mean      | 599      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3676     |\n","|    fps              | 253      |\n","|    time_elapsed     | 3450     |\n","|    total_timesteps  | 873966   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0213   |\n","|    n_updates        | 193491   |\n","----------------------------------\n","Eval num_timesteps=875000, episode_reward=604.00 +/- 119.01\n","Episode length: 4452.60 +/- 567.61\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 4.45e+03 |\n","|    mean_reward      | 604      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 875000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0169   |\n","|    n_updates        | 193749   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.21e+03 |\n","|    ep_rew_mean      | 602      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3680     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3469     |\n","|    total_timesteps  | 875636   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0197   |\n","|    n_updates        | 193908   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.21e+03 |\n","|    ep_rew_mean      | 602      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3684     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3472     |\n","|    total_timesteps  | 876406   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0189   |\n","|    n_updates        | 194101   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.21e+03 |\n","|    ep_rew_mean      | 604      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3688     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3479     |\n","|    total_timesteps  | 878317   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0182   |\n","|    n_updates        | 194579   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.2e+03  |\n","|    ep_rew_mean      | 602      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3692     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3486     |\n","|    total_timesteps  | 880185   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0464   |\n","|    n_updates        | 195046   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.19e+03 |\n","|    ep_rew_mean      | 604      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3696     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3496     |\n","|    total_timesteps  | 882553   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0146   |\n","|    n_updates        | 195638   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.17e+03 |\n","|    ep_rew_mean      | 601      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3700     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3502     |\n","|    total_timesteps  | 884042   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0238   |\n","|    n_updates        | 196010   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.17e+03 |\n","|    ep_rew_mean      | 602      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3704     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3507     |\n","|    total_timesteps  | 885306   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.016    |\n","|    n_updates        | 196326   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.16e+03 |\n","|    ep_rew_mean      | 601      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3708     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3513     |\n","|    total_timesteps  | 887007   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0305   |\n","|    n_updates        | 196751   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.18e+03 |\n","|    ep_rew_mean      | 603      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3712     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3520     |\n","|    total_timesteps  | 888781   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0254   |\n","|    n_updates        | 197195   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.17e+03 |\n","|    ep_rew_mean      | 602      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3716     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3523     |\n","|    total_timesteps  | 889598   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0252   |\n","|    n_updates        | 197399   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.15e+03 |\n","|    ep_rew_mean      | 600      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3720     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3529     |\n","|    total_timesteps  | 891070   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00962  |\n","|    n_updates        | 197767   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.14e+03 |\n","|    ep_rew_mean      | 601      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3724     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3534     |\n","|    total_timesteps  | 892574   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0143   |\n","|    n_updates        | 198143   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.18e+03 |\n","|    ep_rew_mean      | 607      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3728     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3541     |\n","|    total_timesteps  | 894387   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0381   |\n","|    n_updates        | 198596   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.17e+03 |\n","|    ep_rew_mean      | 608      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3732     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3548     |\n","|    total_timesteps  | 896207   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0372   |\n","|    n_updates        | 199051   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.16e+03 |\n","|    ep_rew_mean      | 605      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3736     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3552     |\n","|    total_timesteps  | 897394   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0391   |\n","|    n_updates        | 199348   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.14e+03 |\n","|    ep_rew_mean      | 601      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3740     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3557     |\n","|    total_timesteps  | 898384   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0238   |\n","|    n_updates        | 199595   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.11e+03 |\n","|    ep_rew_mean      | 593      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3744     |\n","|    fps              | 252      |\n","|    time_elapsed     | 3561     |\n","|    total_timesteps  | 899544   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0174   |\n","|    n_updates        | 199885   |\n","----------------------------------\n","Eval num_timesteps=900000, episode_reward=681.00 +/- 233.31\n","Episode length: 4464.20 +/- 1234.47\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 4.46e+03 |\n","|    mean_reward      | 681      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 900000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0185   |\n","|    n_updates        | 199999   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.09e+03 |\n","|    ep_rew_mean      | 593      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3748     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3577     |\n","|    total_timesteps  | 900556   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.018    |\n","|    n_updates        | 200138   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.06e+03 |\n","|    ep_rew_mean      | 588      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3752     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3582     |\n","|    total_timesteps  | 901725   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0212   |\n","|    n_updates        | 200431   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.06e+03 |\n","|    ep_rew_mean      | 590      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3756     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3586     |\n","|    total_timesteps  | 902878   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0659   |\n","|    n_updates        | 200719   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.02e+03 |\n","|    ep_rew_mean      | 586      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3760     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3591     |\n","|    total_timesteps  | 904141   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0146   |\n","|    n_updates        | 201035   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.02e+03 |\n","|    ep_rew_mean      | 586      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3764     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3596     |\n","|    total_timesteps  | 905320   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0417   |\n","|    n_updates        | 201329   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.99e+03 |\n","|    ep_rew_mean      | 582      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3768     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3600     |\n","|    total_timesteps  | 906382   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0241   |\n","|    n_updates        | 201595   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.96e+03 |\n","|    ep_rew_mean      | 580      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3772     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3604     |\n","|    total_timesteps  | 907611   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0211   |\n","|    n_updates        | 201902   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.96e+03 |\n","|    ep_rew_mean      | 581      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3776     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3610     |\n","|    total_timesteps  | 909102   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0218   |\n","|    n_updates        | 202275   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.96e+03 |\n","|    ep_rew_mean      | 582      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3780     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3615     |\n","|    total_timesteps  | 910322   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0205   |\n","|    n_updates        | 202580   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.96e+03 |\n","|    ep_rew_mean      | 584      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3784     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3622     |\n","|    total_timesteps  | 912153   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0224   |\n","|    n_updates        | 203038   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.98e+03 |\n","|    ep_rew_mean      | 586      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3788     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3627     |\n","|    total_timesteps  | 913512   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0131   |\n","|    n_updates        | 203377   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.98e+03 |\n","|    ep_rew_mean      | 585      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3792     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3634     |\n","|    total_timesteps  | 915307   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0368   |\n","|    n_updates        | 203826   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.98e+03 |\n","|    ep_rew_mean      | 584      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3796     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3642     |\n","|    total_timesteps  | 917450   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0107   |\n","|    n_updates        | 204362   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.98e+03 |\n","|    ep_rew_mean      | 583      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3800     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3647     |\n","|    total_timesteps  | 918833   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0151   |\n","|    n_updates        | 204708   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.98e+03 |\n","|    ep_rew_mean      | 582      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3804     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3654     |\n","|    total_timesteps  | 920617   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0559   |\n","|    n_updates        | 205154   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.99e+03 |\n","|    ep_rew_mean      | 580      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3808     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3658     |\n","|    total_timesteps  | 921692   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.011    |\n","|    n_updates        | 205422   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.99e+03 |\n","|    ep_rew_mean      | 581      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3812     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3665     |\n","|    total_timesteps  | 923387   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0121   |\n","|    n_updates        | 205846   |\n","----------------------------------\n","Eval num_timesteps=925000, episode_reward=642.00 +/- 198.69\n","Episode length: 4874.60 +/- 1346.01\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 4.87e+03 |\n","|    mean_reward      | 642      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 925000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0256   |\n","|    n_updates        | 206249   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.04e+03 |\n","|    ep_rew_mean      | 589      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3816     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3687     |\n","|    total_timesteps  | 925851   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0125   |\n","|    n_updates        | 206462   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.04e+03 |\n","|    ep_rew_mean      | 588      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3820     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3694     |\n","|    total_timesteps  | 927515   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0116   |\n","|    n_updates        | 206878   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.99e+03 |\n","|    ep_rew_mean      | 581      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3824     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3704     |\n","|    total_timesteps  | 929945   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0232   |\n","|    n_updates        | 207486   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.99e+03 |\n","|    ep_rew_mean      | 580      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3828     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3709     |\n","|    total_timesteps  | 931351   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0253   |\n","|    n_updates        | 207837   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.97e+03 |\n","|    ep_rew_mean      | 584      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3832     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3713     |\n","|    total_timesteps  | 932474   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0161   |\n","|    n_updates        | 208118   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.97e+03 |\n","|    ep_rew_mean      | 586      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3836     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3721     |\n","|    total_timesteps  | 934589   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0281   |\n","|    n_updates        | 208647   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.97e+03 |\n","|    ep_rew_mean      | 587      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3840     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3728     |\n","|    total_timesteps  | 936452   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0218   |\n","|    n_updates        | 209112   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.98e+03 |\n","|    ep_rew_mean      | 590      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3844     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3733     |\n","|    total_timesteps  | 937784   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0112   |\n","|    n_updates        | 209445   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.99e+03 |\n","|    ep_rew_mean      | 594      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3848     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3742     |\n","|    total_timesteps  | 940082   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0155   |\n","|    n_updates        | 210020   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4e+03    |\n","|    ep_rew_mean      | 596      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3852     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3748     |\n","|    total_timesteps  | 941835   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0492   |\n","|    n_updates        | 210458   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.03e+03 |\n","|    ep_rew_mean      | 601      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3856     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3756     |\n","|    total_timesteps  | 943719   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0126   |\n","|    n_updates        | 210929   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.05e+03 |\n","|    ep_rew_mean      | 604      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3860     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3762     |\n","|    total_timesteps  | 945536   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0165   |\n","|    n_updates        | 211383   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.01e+03 |\n","|    ep_rew_mean      | 599      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3864     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3767     |\n","|    total_timesteps  | 946686   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0269   |\n","|    n_updates        | 211671   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.03e+03 |\n","|    ep_rew_mean      | 599      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3868     |\n","|    fps              | 251      |\n","|    time_elapsed     | 3774     |\n","|    total_timesteps  | 948431   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0591   |\n","|    n_updates        | 212107   |\n","----------------------------------\n","Eval num_timesteps=950000, episode_reward=694.00 +/- 248.02\n","Episode length: 3929.80 +/- 1495.19\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 3.93e+03 |\n","|    mean_reward      | 694      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 950000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0146   |\n","|    n_updates        | 212499   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.03e+03 |\n","|    ep_rew_mean      | 599      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3872     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3792     |\n","|    total_timesteps  | 950051   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0358   |\n","|    n_updates        | 212512   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.96e+03 |\n","|    ep_rew_mean      | 592      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3876     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3799     |\n","|    total_timesteps  | 951902   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0286   |\n","|    n_updates        | 212975   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.99e+03 |\n","|    ep_rew_mean      | 599      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3880     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3806     |\n","|    total_timesteps  | 953751   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0262   |\n","|    n_updates        | 213437   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.93e+03 |\n","|    ep_rew_mean      | 593      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3884     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3810     |\n","|    total_timesteps  | 954802   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0173   |\n","|    n_updates        | 213700   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.94e+03 |\n","|    ep_rew_mean      | 601      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3888     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3817     |\n","|    total_timesteps  | 956739   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0207   |\n","|    n_updates        | 214184   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.95e+03 |\n","|    ep_rew_mean      | 607      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3892     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3825     |\n","|    total_timesteps  | 958595   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0243   |\n","|    n_updates        | 214648   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.94e+03 |\n","|    ep_rew_mean      | 604      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3896     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3830     |\n","|    total_timesteps  | 960080   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0202   |\n","|    n_updates        | 215019   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.93e+03 |\n","|    ep_rew_mean      | 603      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3900     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3835     |\n","|    total_timesteps  | 961343   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0183   |\n","|    n_updates        | 215335   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.92e+03 |\n","|    ep_rew_mean      | 601      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3904     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3841     |\n","|    total_timesteps  | 962802   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00662  |\n","|    n_updates        | 215700   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.89e+03 |\n","|    ep_rew_mean      | 599      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3908     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3846     |\n","|    total_timesteps  | 964212   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0716   |\n","|    n_updates        | 216052   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.88e+03 |\n","|    ep_rew_mean      | 595      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3912     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3851     |\n","|    total_timesteps  | 965523   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00652  |\n","|    n_updates        | 216380   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.89e+03 |\n","|    ep_rew_mean      | 597      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3916     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3859     |\n","|    total_timesteps  | 967761   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.014    |\n","|    n_updates        | 216940   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.92e+03 |\n","|    ep_rew_mean      | 604      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3920     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3866     |\n","|    total_timesteps  | 969511   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.021    |\n","|    n_updates        | 217377   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.95e+03 |\n","|    ep_rew_mean      | 608      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3924     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3878     |\n","|    total_timesteps  | 972540   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00985  |\n","|    n_updates        | 218134   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.95e+03 |\n","|    ep_rew_mean      | 610      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3928     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3884     |\n","|    total_timesteps  | 974400   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0274   |\n","|    n_updates        | 218599   |\n","----------------------------------\n","Eval num_timesteps=975000, episode_reward=557.00 +/- 153.35\n","Episode length: 4336.20 +/- 979.91\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 4.34e+03 |\n","|    mean_reward      | 557      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 975000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0477   |\n","|    n_updates        | 218749   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.96e+03 |\n","|    ep_rew_mean      | 611      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3932     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3904     |\n","|    total_timesteps  | 976157   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0211   |\n","|    n_updates        | 219039   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.95e+03 |\n","|    ep_rew_mean      | 610      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3936     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3906     |\n","|    total_timesteps  | 976872   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0113   |\n","|    n_updates        | 219217   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 3.96e+03 |\n","|    ep_rew_mean      | 610      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3940     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3915     |\n","|    total_timesteps  | 979344   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0323   |\n","|    n_updates        | 219835   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4e+03    |\n","|    ep_rew_mean      | 610      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3944     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3921     |\n","|    total_timesteps  | 980749   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.012    |\n","|    n_updates        | 220187   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.05e+03 |\n","|    ep_rew_mean      | 619      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3948     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3932     |\n","|    total_timesteps  | 983575   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0172   |\n","|    n_updates        | 220893   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.04e+03 |\n","|    ep_rew_mean      | 620      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3952     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3935     |\n","|    total_timesteps  | 984481   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0189   |\n","|    n_updates        | 221120   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.04e+03 |\n","|    ep_rew_mean      | 621      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3956     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3941     |\n","|    total_timesteps  | 986062   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0152   |\n","|    n_updates        | 221515   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.04e+03 |\n","|    ep_rew_mean      | 619      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3960     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3948     |\n","|    total_timesteps  | 987960   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0151   |\n","|    n_updates        | 221989   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.05e+03 |\n","|    ep_rew_mean      | 627      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3964     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3955     |\n","|    total_timesteps  | 989816   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0255   |\n","|    n_updates        | 222453   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.07e+03 |\n","|    ep_rew_mean      | 628      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3968     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3960     |\n","|    total_timesteps  | 990988   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0353   |\n","|    n_updates        | 222746   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.09e+03 |\n","|    ep_rew_mean      | 631      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3972     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3967     |\n","|    total_timesteps  | 993065   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.012    |\n","|    n_updates        | 223266   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.09e+03 |\n","|    ep_rew_mean      | 633      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3976     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3973     |\n","|    total_timesteps  | 994547   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.018    |\n","|    n_updates        | 223636   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.05e+03 |\n","|    ep_rew_mean      | 629      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3980     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3978     |\n","|    total_timesteps  | 996058   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0135   |\n","|    n_updates        | 224014   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.05e+03 |\n","|    ep_rew_mean      | 626      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3984     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3988     |\n","|    total_timesteps  | 998550   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.044    |\n","|    n_updates        | 224637   |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 4.09e+03 |\n","|    ep_rew_mean      | 637      |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    episodes         | 3988     |\n","|    fps              | 250      |\n","|    time_elapsed     | 3992     |\n","|    total_timesteps  | 999779   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.02     |\n","|    n_updates        | 224944   |\n","----------------------------------\n","Eval num_timesteps=1000000, episode_reward=489.00 +/- 91.07\n","Episode length: 3543.80 +/- 698.17\n","----------------------------------\n","| eval/               |          |\n","|    mean_ep_length   | 3.54e+03 |\n","|    mean_reward      | 489      |\n","| rollout/            |          |\n","|    exploration_rate | 0.01     |\n","| time/               |          |\n","|    total_timesteps  | 1000000  |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.0212   |\n","|    n_updates        | 224999   |\n","----------------------------------\n","Saving to logs//dqn/SpaceInvadersNoFrameskip-v4_1\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"RWqy9kq2F0nf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# lets evaluate our agent:\n","- RL-Baselines3-Zoo provides `enjoy.py`, a python script to evaluate our agent. In most RL libraries, we call the evaluation script `enjoy.py`.\n","- Let's evaluate it for 5000 timesteps 🔥"],"metadata":{"id":"wUBRZRg5F0qp"}},{"cell_type":"code","source":["!python -m rl_zoo3.enjoy  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --no-render  --n-timesteps 5000  --folder logs/"],"metadata":{"id":"-w6XrAoFF0uJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715355106454,"user_tz":-330,"elapsed":21773,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}},"outputId":"491320ed-34b5-450b-c59a-37de31826ef3"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-05-10 15:31:26.738186: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-10 15:31:26.738236: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-10 15:31:26.739555: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-10 15:31:26.746408: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-10 15:31:27.825132: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Loading latest experiment, id=1\n","Loading logs/dqn/SpaceInvadersNoFrameskip-v4_1/SpaceInvadersNoFrameskip-v4.zip\n","A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n","[Powered by Stella]\n","Stacking 4 frames\n","Atari Episode Score: 545.00\n","Atari Episode Length 3429\n","Atari Episode Score: 545.00\n","Atari Episode Length 3449\n","Atari Episode Score: 1435.00\n","Atari Episode Length 7665\n","Atari Episode Score: 650.00\n","Atari Episode Length 3825\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ogLsrd6cIevV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# publish our trained model to the hub:"],"metadata":{"id":"ZwnBVxWWIe4e"}},{"cell_type":"code","source":["from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n","notebook_login()\n","!git config --global credential.helper store"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["917e3d7db1cc499e8eb23b890b57522c","d85981ec931741b8b8a57ba31b361204","4094376eb3074f1796aec1018c029fff","315adadd8d3342b79699ce4e51ff7b33","45f86d04ed914234b6a20e8f4ef4100a","1db52c63f7f0461aa4c6503d01d8ecf6","ca6113873544454ca688f17359d0b010","58d3b8929d79495d9b38229c85436bc6","55ce120e8a0440c3b86810f020d592d0","e0898acaad7a4bfea9e7b188bcc70dc2","550fa2ddca2b48f8a21a29f38db8e850","e656de3304404456b212eec1a231de56","3eef8bc8bc864c4a860d905d3e40dfff","6ea3cdda16ff4018bef011003e63f976","29ff26b50b4f4a1ca7c8c6dd632fc86f","772571ca903d4da8bbcf0fd19e83d4e3","70c645c7cf5241b297fdcf1ef62e57e4","59752a1b9dda486bbd04bca367f35b45","8990f1e4dadf4d34a08cee583ecb8885","47f70941685d495696efc58e9e834edf","061f7696eba048c79e68c37185979d33","2faad385ac4344b7bfd81a1ae12b03d4","c34208ca867242ffad430c5dc7ec95ba","fe3dc12d28e8421ab91494d68585ce35","d9194497629647a78d0f71862ce9aa17","9d6ee07350164dbab5c645028b950aee","9b17ed949a88415583e83158f7ca4461","bb8b73caceee4e239822d6ff1a1837ae","bf35d14dc62c4076bef905e7d8d2b570","aa2478e43bb640bfa7c8fd06f7de491b","c6f56e5c6ac5421e8f6289c7d9cb8143","c76db16b5a8743b2b25ed3258a77dd5e"]},"id":"OoEgboZkIpp7","executionInfo":{"status":"ok","timestamp":1715355277508,"user_tz":-330,"elapsed":557,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}},"outputId":"ccd0c045-8a9c-456a-8662-58e76d7f395c"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"917e3d7db1cc499e8eb23b890b57522c"}},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"_Z2i_09uIpsx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3️⃣ We're now ready to push our trained agent to the 🤗 Hub 🔥"],"metadata":{"id":"dTE1CNl4Ie7W"}},{"cell_type":"markdown","source":["Let's run push_to_hub.py file to upload our trained agent to the Hub.\n","\n","`--repo-name `: The name of the repo\n","\n","`-orga`: Your Hugging Face username\n","\n","`-f`: Where the trained model folder is (in our case `logs`)"],"metadata":{"id":"FXo7fvPbJQx_"}},{"cell_type":"code","source":["!python -m rl_zoo3.push_to_hub  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --repo-name atari_games_playing_agent -orga GeorgeImmanuel -f logs/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"40LoQ68fJQ0x","executionInfo":{"status":"ok","timestamp":1715355500520,"user_tz":-330,"elapsed":52121,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}},"outputId":"ac3a0a54-f7a7-463c-ff88-32f3e106eae3"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-05-10 15:37:30.946129: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-10 15:37:30.946184: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-10 15:37:30.947721: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-10 15:37:30.955574: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-10 15:37:32.034109: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Loading latest experiment, id=1\n","Loading logs/dqn/SpaceInvadersNoFrameskip-v4_1/SpaceInvadersNoFrameskip-v4.zip\n","A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n","[Powered by Stella]\n","Stacking 4 frames\n","Wrapping the env in a VecTransposeImage.\n","Uploading to GeorgeImmanuel/atari_games_playing_agent, make sure to have the rights\n","\u001b[38;5;4mℹ This function will save, evaluate, generate a video of your agent,\n","create a model card and push everything to the hub. It might take up to some\n","minutes if video generation is activated. This is a work in progress: if you\n","encounter a bug, please open an issue.\u001b[0m\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n","For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n","  warnings.warn(warning_message, FutureWarning)\n","Cloning https://huggingface.co/GeorgeImmanuel/atari_games_playing_agent into local empty directory.\n","WARNING:huggingface_hub.repository:Cloning https://huggingface.co/GeorgeImmanuel/atari_games_playing_agent into local empty directory.\n","Saving model to: hub/atari_games_playing_agent/dqn-SpaceInvadersNoFrameskip-v4\n","/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:335: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n","  logger.warn(\n","Saving video to /tmp/tmpa01zbvvb/-step-0-to-step-1000.mp4\n","Moviepy - Building video /tmp/tmpa01zbvvb/-step-0-to-step-1000.mp4.\n","Moviepy - Writing video /tmp/tmpa01zbvvb/-step-0-to-step-1000.mp4\n","\n","Moviepy - Done !\n","Moviepy - video ready /tmp/tmpa01zbvvb/-step-0-to-step-1000.mp4\n","ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n","  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n","  libavutil      56. 70.100 / 56. 70.100\n","  libavcodec     58.134.100 / 58.134.100\n","  libavformat    58. 76.100 / 58. 76.100\n","  libavdevice    58. 13.100 / 58. 13.100\n","  libavfilter     7.110.100 /  7.110.100\n","  libswscale      5.  9.100 /  5.  9.100\n","  libswresample   3.  9.100 /  3.  9.100\n","  libpostproc    55.  9.100 / 55.  9.100\n","Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/tmp/tmpa01zbvvb/-step-0-to-step-1000.mp4':\n","  Metadata:\n","    major_brand     : isom\n","    minor_version   : 512\n","    compatible_brands: isomiso2avc1mp41\n","    encoder         : Lavf58.29.100\n","  Duration: 00:00:33.40, start: 0.000000, bitrate: 49 kb/s\n","  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 160x210, 46 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n","    Metadata:\n","      handler_name    : VideoHandler\n","      vendor_id       : [0][0][0][0]\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n","Press [q] to stop, [?] for help\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mprofile High, level 1.2, 4:2:0, 8-bit\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n","Output #0, mp4, to 'hub/atari_games_playing_agent/replay.mp4':\n","  Metadata:\n","    major_brand     : isom\n","    minor_version   : 512\n","    compatible_brands: isomiso2avc1mp41\n","    encoder         : Lavf58.76.100\n","  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 160x210, q=2-31, 30 fps, 15360 tbn (default)\n","    Metadata:\n","      handler_name    : VideoHandler\n","      vendor_id       : [0][0][0][0]\n","      encoder         : Lavc58.134.100 libx264\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n","frame= 1002 fps=0.0 q=-1.0 Lsize=     195kB time=00:00:33.30 bitrate=  47.9kbits/s speed=40.3x    \n","video:184kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 5.780948%\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mframe I:5     Avg QP:17.84  size:  2561\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mframe P:526   Avg QP:22.65  size:   288\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mframe B:471   Avg QP:29.45  size:    49\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mconsecutive B-frames: 30.8% 16.6%  8.7% 43.9%\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mmb I  I16..4: 17.0% 45.4% 37.6%\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mmb P  I16..4:  0.4%  0.9%  0.8%  P16..4:  7.3%  2.4%  1.4%  0.0%  0.0%    skip:86.8%\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mmb B  I16..4:  0.2%  0.1%  0.1%  B16..8:  9.2%  0.8%  0.1%  direct: 0.2%  skip:89.4%  L0:51.6% L1:48.0% BI: 0.4%\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0m8x8 transform intra:43.4% inter:6.2%\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mcoded y,uvDC,uvAC intra: 20.2% 37.2% 34.2% inter: 1.3% 1.5% 1.2%\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mi16 v,h,dc,p: 40% 55%  5%  0%\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 27%  8% 64%  1%  0%  0%  0%  0%  0%\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 32% 13% 45%  2%  2%  2%  1%  2%  1%\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mi8c dc,h,v,p: 56% 31% 13%  1%\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mref P L0: 76.2%  4.4% 10.7%  8.7%\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mref B L0: 84.5% 12.6%  2.9%\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mref B L1: 97.2%  2.8%\n","\u001b[1;36m[libx264 @ 0x5a415831ad80] \u001b[0mkb/s:44.96\n","\u001b[38;5;4mℹ Pushing repo atari_games_playing_agent to the Hugging Face Hub\u001b[0m\n","Upload file dqn-SpaceInvadersNoFrameskip-v4.zip:   0% 1.00/26.0M [00:00<?, ?B/s]\n","Upload file replay.mp4:   0% 1.00/195k [00:00<?, ?B/s]\u001b[A\n","\n","Upload file train_eval_metrics.zip:   0% 1.00/36.6k [00:00<?, ?B/s]\u001b[A\u001b[A\n","\n","\n","Upload file dqn-SpaceInvadersNoFrameskip-v4/policy.optimizer.pth:   0% 1.00/12.9M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Upload file dqn-SpaceInvadersNoFrameskip-v4/pytorch_variables.pth:   0% 1.00/864 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Upload file dqn-SpaceInvadersNoFrameskip-v4/policy.pth:   0% 1.00/12.9M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n","Upload file replay.mp4: 15.3MB [00:01, 16.0MB/s]      \u001b[A\n","\n","\n","Upload file dqn-SpaceInvadersNoFrameskip-v4/policy.optimizer.pth: 15.3MB [00:01, 16.0MB/s]       \u001b[A\u001b[A\u001b[A\n","\n","\n","\n","\n","Upload file dqn-SpaceInvadersNoFrameskip-v4.zip: 30.5MB [00:02, 16.0MB/s]                To https://huggingface.co/GeorgeImmanuel/atari_games_playing_agent\n","   f9ab20e..738e19f  main -> main\n","\n","WARNING:huggingface_hub.repository:To https://huggingface.co/GeorgeImmanuel/atari_games_playing_agent\n","   f9ab20e..738e19f  main -> main\n","\n","Upload file dqn-SpaceInvadersNoFrameskip-v4.zip: 100% 26.0M/26.0M [00:03<00:00, 9.06MB/s]\n","\n","Upload file replay.mp4: 100% 195k/195k [00:03<00:00, 66.3kB/s]\n","\n","\n","Upload file train_eval_metrics.zip: 100% 36.6k/36.6k [00:03<00:00, 5.32MB/s]\u001b[A\u001b[A\n","\n","Upload file train_eval_metrics.zip: 100% 36.6k/36.6k [00:03<00:00, 12.5kB/s]\n","\n","\n","\n","Upload file dqn-SpaceInvadersNoFrameskip-v4/policy.optimizer.pth: 100% 12.9M/12.9M [00:03<00:00, 4.49MB/s]\n","\n","\n","\n","\n","Upload file dqn-SpaceInvadersNoFrameskip-v4/pytorch_variables.pth: 100% 864/864 [00:03<00:00, 5.32MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","Upload file dqn-SpaceInvadersNoFrameskip-v4/pytorch_variables.pth: 100% 864/864 [00:03<00:00, 287B/s]  \n","\n","\n","\n","\n","\n","Upload file dqn-SpaceInvadersNoFrameskip-v4/policy.pth: 100% 12.9M/12.9M [00:03<00:00, 4.49MB/s]\n","\u001b[38;5;4mℹ Your model is pushed to the hub. You can view your model here:\n","https://huggingface.co/GeorgeImmanuel/atari_games_playing_agent\u001b[0m\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cl82thvsJQ4o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load a powerful trained model 🔥\n","- The Stable-Baselines3 team uploaded **more than 150 trained Deep Reinforcement Learning agents on the Hub**.\n","\n","You can find them here: 👉 https://huggingface.co/sb3\n","\n","Some examples:\n","- Asteroids: https://huggingface.co/sb3/dqn-AsteroidsNoFrameskip-v4\n","- Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4\n","- Breakout: https://huggingface.co/sb3/dqn-BreakoutNoFrameskip-v4\n","- Road Runner: https://huggingface.co/sb3/dqn-RoadRunnerNoFrameskip-v4\n","\n","Let's load an agent playing Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4"],"metadata":{"id":"sRUKlNSKLWRh"}},{"cell_type":"code","source":[],"metadata":{"id":"XTFdLO7KLWVC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<video controls autoplay><source src=\"https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"],"metadata":{"id":"vQX9CoIrLhqp"}},{"cell_type":"code","source":["!python -m rl_zoo3.load_from_hub --algo dqn --env BeamRiderNoFrameskip-v4 -orga sb3 -f rl_trained/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z4_GD1HoLky7","executionInfo":{"status":"ok","timestamp":1715356261158,"user_tz":-330,"elapsed":8982,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}},"outputId":"e2d79abb-e83c-46a9-df9b-c70d833c25be"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-05-10 15:50:54.514781: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-10 15:50:54.514855: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-10 15:50:54.516890: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-10 15:50:54.527370: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-10 15:50:56.122033: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Downloading from https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4\n","dqn-BeamRiderNoFrameskip-v4.zip: 100% 27.2M/27.2M [00:00<00:00, 114MB/s] \n","config.yml: 100% 548/548 [00:00<00:00, 3.11MB/s]\n","No normalization file\n","args.yml: 100% 887/887 [00:00<00:00, 4.48MB/s]\n","env_kwargs.yml: 100% 3.00/3.00 [00:00<00:00, 14.1kB/s]\n","train_eval_metrics.zip: 100% 244k/244k [00:00<00:00, 146MB/s]\n","Saving to rl_trained/dqn/BeamRiderNoFrameskip-v4_1\n"]}]},{"cell_type":"markdown","source":["### 2. let's train it for 5000 steps"],"metadata":{"id":"1VMZSSjjLk2a"}},{"cell_type":"code","source":["!python -m rl_zoo3.enjoy --algo dqn --env BeamRiderNoFrameskip-v4 -n 5000  -f rl_trained/ --no-render"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfPZUIOeNFcA","executionInfo":{"status":"ok","timestamp":1715356375822,"user_tz":-330,"elapsed":22418,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}},"outputId":"a2e33990-b37a-40d9-b690-3a6ed37acf82"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-05-10 15:52:35.611441: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-10 15:52:35.611488: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-10 15:52:35.612851: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-10 15:52:35.620277: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-10 15:52:36.686010: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Loading latest experiment, id=1\n","Loading rl_trained/dqn/BeamRiderNoFrameskip-v4_1/BeamRiderNoFrameskip-v4.zip\n","A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n","[Powered by Stella]\n","Stacking 4 frames\n","/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object exploration_schedule. Consider using `custom_objects` argument to replace this object.\n","Exception: 'bytes' object cannot be interpreted as an integer\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:95: UserWarning: You loaded a model that was trained using OpenAI Gym. We strongly recommend transitioning to Gymnasium by saving that model again.\n","  warnings.warn(\n","Atari Episode Score: 3028.00\n","Atari Episode Length 14816\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GWGksvibNFfG"},"execution_count":null,"outputs":[]}]}