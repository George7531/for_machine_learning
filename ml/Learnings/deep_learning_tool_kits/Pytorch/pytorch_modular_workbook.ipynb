{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNdkXxnyBxT4N7esKpxW1VZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# day 260,day 262,day 264"],"metadata":{"id":"i77-vYC7QWpR"}},{"cell_type":"markdown","source":["# lets build two parts:\n","1. cell mode\n","2. script mode."],"metadata":{"id":"Ok_f_SOwWWQG"}},{"cell_type":"code","source":[],"metadata":{"id":"8jNBcXrAWelX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. fulfill the cell mode:\n","\n","## goals:\n","1. import the essentials.\n","2. download the data\n","3. make custom image folder and apply data augmentations to each image in train_data and test_data.\n","4. batchify the images\n","5. create TinyVGG model\n","6. fit and evaluate the model.\n","7. save the model with pth extension."],"metadata":{"id":"YrUkSFHUYmEP"}},{"cell_type":"markdown","source":["# importing the essentials:"],"metadata":{"id":"RlHEAS9nRWWm"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torchvision\n","import os,requests,zipfile\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix,classification_report\n","from mlxtend.plotting import plot_confusion_matrix\n","from PIL import Image\n","from pathlib import Path\n","from tqdm.auto import tqdm\n","import time"],"metadata":{"id":"voeH9oB9RWct","executionInfo":{"status":"ok","timestamp":1703162375956,"user_tz":-330,"elapsed":13922,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"53tqGserYe3t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# downloading the data"],"metadata":{"id":"TfxJ3TttYfVk"}},{"cell_type":"code","source":["# creating the directories for storage.\n","data = Path('data')\n","images_folder = data / 'images'\n","images_folder.mkdir(parents=True,exist_ok=True)\n","\n","# downloading the data:\n","with open(data / 'pizza_steak_sushi.zip','wb') as f:\n","  link = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\").content\n","  f.write(link)\n","\n","\n","# unzip the file\n","with zipfile.ZipFile(data/'pizza_steak_sushi.zip','r') as zip:\n","  zip.extractall(images_folder)\n","  zip.close()"],"metadata":{"id":"VpQ1iDiVWSPH","executionInfo":{"status":"ok","timestamp":1703162382807,"user_tz":-330,"elapsed":1933,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Jjp0ISMsYA8x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# create custom image folder"],"metadata":{"id":"75rGUUYTYit5"}},{"cell_type":"code","source":["def find_classes(directory):\n","  class_names = sorted(os.listdir(directory))\n","\n","  if not class_names:\n","    raise FileNotFoundError(\"The {} is not correct. please check!!\".format(directory))\n","\n","  class_idx = {class_names:idx for idx,class_names in enumerate(class_names)}\n","\n","  return class_names,class_idx"],"metadata":{"id":"hgMwWHnTZ665","executionInfo":{"status":"ok","timestamp":1703162864957,"user_tz":-330,"elapsed":448,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class CustomImageFolder(torch.utils.data.Dataset):\n","\n","  # initializer\n","  def __init__(self,directory,transform=None):\n","    self.image_paths = list(Path(directory).glob('*/*.jpg'))\n","    self.transform = transform\n","    self.class_names, self.class_idx = find_classes(directory)\n","\n","  # load the image:\n","  def load_image(self,index):\n","    return Image.open(self.image_paths[index])\n","\n","  # overwrite the len\n","  def __len__(self):\n","    return len(self.image_paths)\n","\n","  # overwrite the getitem function\n","  def __getitem__(self,index):\n","    image = self.load_image(index)\n","    class_name = self.image_paths[index].parent.stem\n","    label = self.class_idx[class_name]\n","\n","    if self.transform:\n","      return self.transform(image),label\n","    else:\n","      return image,label"],"metadata":{"id":"af1S6IvbbIWJ","executionInfo":{"status":"ok","timestamp":1703162865639,"user_tz":-330,"elapsed":21,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train_dir = 'data/images/train'\n","test_dir = 'data/images/test'\n","\n","train_augmentation = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize(size=[64,64]),\n","    torchvision.transforms.TrivialAugmentWide(num_magnitude_bins=31),\n","    torchvision.transforms.ToTensor()\n","])\n","\n","test_augmentation = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize(size=[64,64]),\n","    torchvision.transforms.ToTensor()\n","])\n","\n","train_data = CustomImageFolder(directory=train_dir,transform=train_augmentation)\n","test_data = CustomImageFolder(directory=test_dir,transform=test_augmentation)"],"metadata":{"id":"xwaOiF5ke9Ii","executionInfo":{"status":"ok","timestamp":1703162865640,"user_tz":-330,"elapsed":20,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KrTXRbiGhTqZ","executionInfo":{"status":"ok","timestamp":1703162865641,"user_tz":-330,"elapsed":20,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Batchify the train_data and test_data(datasets to dataloader):"],"metadata":{"id":"GsBOrTvvhT0w"}},{"cell_type":"code","source":["train_dataloader = torch.utils.data.DataLoader(train_data,\n","                                               batch_size=32,\n","                                               shuffle=True,\n","                                               num_workers=os.cpu_count())\n","\n","test_dataloader = torch.utils.data.DataLoader(test_data,\n","                                              batch_size=32,\n","                                              shuffle=False,\n","                                              num_workers=os.cpu_count())"],"metadata":{"id":"6H8cWpHrhcGe","executionInfo":{"status":"ok","timestamp":1703162865641,"user_tz":-330,"elapsed":19,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cfpiJrO5hO4p","executionInfo":{"status":"ok","timestamp":1703162865642,"user_tz":-330,"elapsed":18,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Create The TinyVGG model"],"metadata":{"id":"eO-sQSu3ivBh"}},{"cell_type":"code","source":["class TinyVGG(torch.nn.Module):\n","  def __init__(self,i,o,h):\n","    super().__init__()\n","\n","    self.conv_block1 = torch.nn.Sequential(\n","        torch.nn.Conv2d(in_channels=i,\n","                        out_channels=h,\n","                        kernel_size=3,\n","                        stride=1,\n","                        padding=1),\n","        torch.nn.ReLU(),\n","        torch.nn.Conv2d(in_channels=h,\n","                        out_channels=h,\n","                        kernel_size=3,\n","                        stride=1,\n","                        padding=1),\n","        torch.nn.ReLU(),\n","        torch.nn.MaxPool2d(kernel_size=3,stride=1)\n","    )\n","\n","    self.conv_block2 = torch.nn.Sequential(\n","        torch.nn.Conv2d(in_channels=h,\n","                        out_channels=h,\n","                        kernel_size=3,\n","                        stride=1,\n","                        padding=1),\n","        torch.nn.ReLU(),\n","        torch.nn.Conv2d(in_channels=h,\n","                        out_channels=h,\n","                        kernel_size=3,\n","                        stride=1,\n","                        padding=1),\n","        torch.nn.ReLU(),\n","        torch.nn.MaxPool2d(kernel_size=3,stride=1)\n","    )\n","\n","    self.classifier = torch.nn.Sequential(\n","        torch.nn.Flatten(),\n","        torch.nn.Linear(in_features=h*3600,out_features=o)\n","    )\n","\n","  def forward(self,x):\n","    return self.classifier(self.conv_block2(self.conv_block1(x)))\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model0 = TinyVGG(i=3,h=10,o=len(train_data.class_names))\n","\n","# compile the model:\n","loss = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params=model0.parameters(),\n","                             lr=0.001)\n","def accuracy(pred,actual):\n","  correct = torch.eq(pred,actual).sum().item()\n","  acc = correct/len(actual)\n","  return acc\n","\n","# fit the model\n","def total_time(start,end):\n","  total_time = end-start\n","  print(\"Total Running TIME: {}\".format(total_time))\n","\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","\n","epochs = 5\n","start = time.perf_counter()\n","\n","trl = []\n","tsl = []\n","tra = []\n","tsa = []\n","\n","for epoch in range(epochs):\n","\n","  a_train_loss,a_test_loss,a_train_acc,a_test_acc = 0,0,0,0\n","\n","  for x_train,y_train in train_dataloader:\n","    x_train,y_train = x_train.to(device),y_train.to(device)\n","\n","    train_logits = model0(x_train)\n","    train_predictions = train_logits.argmax(dim=1)\n","    train_actuals = y_train\n","    train_loss = loss(train_logits,train_actuals)\n","    train_accuracy = accuracy(train_predictions,train_actuals)\n","    a_train_loss += train_loss\n","    a_train_acc += train_accuracy\n","\n","    # zero grad the optimizer\n","    optimizer.zero_grad()\n","\n","    # backpropogate the train_loss\n","    train_loss.backward()\n","\n","    # step the optimizer up a notch\n","    optimizer.step()\n","\n","  # normalizing the accumulated losses and accuracies\n","  a_train_loss /= len(train_dataloader)\n","  a_train_acc /= len(train_dataloader)\n","\n","  # evaluate\n","  model0.eval()\n","  with torch.inference_mode():\n","    for x_test,y_test in test_dataloader:\n","      x_test,y_test = x_test.to(device),y_test.to(device)\n","\n","      test_logits = model0(x_test)\n","      test_predictions = test_logits.argmax(dim=1)\n","      test_actuals = y_test\n","      test_loss = loss(test_logits,test_predictions)\n","      test_accuracy = accuracy(test_predictions,test_actuals)\n","      a_test_loss += test_loss\n","      a_test_acc += test_accuracy\n","\n","    # normalizing the accumulated test loss and test accuracy\n","    a_test_loss /= len(test_dataloader)\n","    a_test_acc /= len(test_dataloader)\n","\n","\n","    # inserting the essentials in the container\n","    trl.append(a_train_loss)\n","    tsl.append(a_test_loss)\n","    tra.append(a_train_acc)\n","    tsa.append(a_test_acc)\n","\n","    print(\"Epoch: {} | Train Loss: {:.3f}, Train Acc: {:.3f} | Test Loss: {:.3f},Test Acc: {:.3f}\"\n","    .format(epoch,a_train_loss,a_train_acc,a_test_loss,a_test_acc))\n","\n","end = time.perf_counter()\n","total_time(start,end)\n","\n","\n","\n"],"metadata":{"id":"p_pG69Nwi2vn","executionInfo":{"status":"ok","timestamp":1703162883473,"user_tz":-330,"elapsed":17847,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"832b07e3-7f8b-4eb5-d2f9-5da9dc19a77b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0 | Train Loss: 1.240, Train Acc: 0.383 | Test Loss: 0.452,Test Acc: 0.323\n","Epoch: 1 | Train Loss: 1.358, Train Acc: 0.246 | Test Loss: 0.819,Test Acc: 0.417\n","Epoch: 2 | Train Loss: 1.102, Train Acc: 0.414 | Test Loss: 0.752,Test Acc: 0.323\n","Epoch: 3 | Train Loss: 1.174, Train Acc: 0.281 | Test Loss: 1.040,Test Acc: 0.260\n","Epoch: 4 | Train Loss: 1.213, Train Acc: 0.305 | Test Loss: 0.831,Test Acc: 0.260\n","Total Running TIME: 17.466580126000053\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"298Bkgy0i3Xg","executionInfo":{"status":"ok","timestamp":1703162883474,"user_tz":-330,"elapsed":39,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# save the model"],"metadata":{"id":"-lrV2cZyIpm1"}},{"cell_type":"code","source":["saved_path = Path('SavedModels')\n","\n","# make a directory\n","saved_path.mkdir(parents=True,exist_ok=True)\n","\n","# creating a name for the model with pth extension\n","model_name = 'model0.pth'\n","\n","# creating the model saved path\n","model_saved_path = saved_path / model_name\n","\n","# save the model\n","saved_model = torch.save(obj=model0.state_dict(),\n","                         f=model_saved_path)"],"metadata":{"id":"Oh24wK3xIsc9","executionInfo":{"status":"ok","timestamp":1703162883475,"user_tz":-330,"elapsed":37,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aWEhfjyXIsgV","executionInfo":{"status":"ok","timestamp":1703162883475,"user_tz":-330,"elapsed":36,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# exploration,analysis and freethrows"],"metadata":{"id":"pIgj4Eeaa8eI"}},{"cell_type":"code","source":["train_data.class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1c6J7sahVm3","executionInfo":{"status":"ok","timestamp":1703162883476,"user_tz":-330,"elapsed":36,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}},"outputId":"c5e390ea-178f-4497-9b52-3e791bcc7c66"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['pizza', 'steak', 'sushi']"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":[],"metadata":{"id":"hTN7i8MRhVqP","executionInfo":{"status":"ok","timestamp":1703162883476,"user_tz":-330,"elapsed":32,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Part 2 script mode\n","\n","## goals:\n","1. write create_dataloader function in a python script file named data_setup.py and import it.\n","2. write build_model function in a python script and name it build_model and import it"],"metadata":{"id":"3hLYi-8PhVtZ"}},{"cell_type":"code","source":["# this is for deleting the going_modular folder incase a new change to be incorporated into the script.\n","!rm -rf going_modular"],"metadata":{"id":"7UQ5cUjzUaoT","executionInfo":{"status":"ok","timestamp":1703162883476,"user_tz":-330,"elapsed":31,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# magics script for datasets and dataloader\n","\n"],"metadata":{"id":"cjvRga81QqFM"}},{"cell_type":"code","source":["# making the 'going_modular' directory\n","folder = Path('going_modular')\n","folder.mkdir(parents=True,exist_ok=True)\n","\n","\n","with open(Path(folder / 'data_setup.py'),'w') as f:\n","  f. write(\"\"\"\n","import torch\n","import torchvision\n","import os\n","def create_dataloaders(train_dir,test_dir,train_augmentation,test_augmentation,BatchSize):\n","  train_data = torchvision.datasets.ImageFolder(root=train_dir,transform=train_augmentation)\n","  test_data =  torchvision.datasets.ImageFolder(root=test_dir,transform=test_augmentation)\n","  class_names = train_data.classes\n","  train_dataloader = torch.utils.data.DataLoader(train_data,\n","                                                    batch_size=BatchSize,\n","                                                    shuffle=True,\n","                                                    num_workers=os.cpu_count(),\n","                                                    pin_memory=True)\n","  test_dataloader = torch.utils.data.DataLoader(test_data,\n","                                                    batch_size=BatchSize,\n","                                                    shuffle=True,\n","                                                    num_workers=os.cpu_count(),\n","                                                  pin_memory=True)\n","  # pin memory does automatic memory transfer from CPU to GPU at a faster rate.\n","\n","  return class_names,train_dataloader,test_dataloader\"\"\"\n","  )"],"metadata":{"id":"KhaeRWFRUgGU","executionInfo":{"status":"ok","timestamp":1703162883477,"user_tz":-330,"elapsed":28,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# import data_setup file from going_modular folder\n","from going_modular import data_setup"],"metadata":{"id":"ECjSJ-BaXgtz","executionInfo":{"status":"ok","timestamp":1703162883477,"user_tz":-330,"elapsed":27,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# create the dataloader and class_names using your scripted file\n","train_dir = 'data/images/train'\n","test_dir = 'data/images/test'\n","class_names, train_dataloader,test_dataloader = data_setup.create_dataloaders(\n","    train_dir,\n","    test_dir,\n","    train_augmentation,\n","    test_augmentation,\n","    32\n",")\n","\n","class_names,train_dataloader,test_dataloader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FJDe1fbLrh1h","executionInfo":{"status":"ok","timestamp":1703162883477,"user_tz":-330,"elapsed":26,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}},"outputId":"7e0d3f24-a223-43b9-ee4b-777daa377f69"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['pizza', 'steak', 'sushi'],\n"," <torch.utils.data.dataloader.DataLoader at 0x7f673f879720>,\n"," <torch.utils.data.dataloader.DataLoader at 0x7f673f87a020>)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":[],"metadata":{"id":"6zX8uBWq10Pp","executionInfo":{"status":"ok","timestamp":1703162883478,"user_tz":-330,"elapsed":23,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# turning our model building code into python script"],"metadata":{"id":"TQtrWoUQ10yX"}},{"cell_type":"code","source":["with open(Path(folder / 'model_building.py'),'w') as f:\n","  f.write(\n","\"\"\"\n","\n","# Args:\n","# 1. it creates the TinyVGG model from CNN Explainer website:\n","# 2. it takes an integer for input(i)_i is number of color channels in the images.\n","# 3. it takes an integer for hidden_layers(h)\n","# 4. it takes and integer for outputs(o)_ which is the number of classes\n","\n","# importing the essentials\n","import torch\n","class TinyVGG(torch.nn.Module):\n","  def __init__(self,i,o,h):\n","    super().__init__()\n","\n","    self.conv_block1 = torch.nn.Sequential(\n","        torch.nn.Conv2d(in_channels=i,\n","                        out_channels=h,\n","                        kernel_size=3,\n","                        stride=1,\n","                        padding=1),\n","        torch.nn.ReLU(),\n","        torch.nn.Conv2d(in_channels=h,\n","                        out_channels=h,\n","                        kernel_size=3,\n","                        stride=1,\n","                        padding=1),\n","        torch.nn.ReLU(),\n","        torch.nn.MaxPool2d(kernel_size=3,stride=1)\n","    )\n","\n","    self.conv_block2 = torch.nn.Sequential(\n","        torch.nn.Conv2d(in_channels=h,\n","                        out_channels=h,\n","                        kernel_size=3,\n","                        stride=1,\n","                        padding=1),\n","        torch.nn.ReLU(),\n","        torch.nn.Conv2d(in_channels=h,\n","                        out_channels=h,\n","                        kernel_size=3,\n","                        stride=1,\n","                        padding=1),\n","        torch.nn.ReLU(),\n","        torch.nn.MaxPool2d(kernel_size=3,stride=1)\n","    )\n","\n","    self.classifier = torch.nn.Sequential(\n","        torch.nn.Flatten(),\n","        torch.nn.Linear(in_features=h*3600,out_features=o)\n","    )\n","\n","  def forward(self,x):\n","    return self.classifier(self.conv_block2(self.conv_block1(x)))\n","\n"," \"\"\"\n","\n","  )\n"],"metadata":{"id":"TKoAfwQe16ns","executionInfo":{"status":"ok","timestamp":1703162883478,"user_tz":-330,"elapsed":23,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# importing the model_building method from the python script\n","from going_modular import model_building\n","\n"],"metadata":{"id":"MdNHwBiH56G2","executionInfo":{"status":"ok","timestamp":1703162883478,"user_tz":-330,"elapsed":22,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# create a model\n","model1 = model_building.TinyVGG(i=3,o=len(class_names),h=10)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model1.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w9mDYlwL6jma","executionInfo":{"status":"ok","timestamp":1703162883479,"user_tz":-330,"elapsed":22,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}},"outputId":"535417b9-a95a-4e6b-d50f-73edbc3f3e46"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TinyVGG(\n","  (conv_block1): Sequential(\n","    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU()\n","    (4): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv_block2): Sequential(\n","    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU()\n","    (4): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=36000, out_features=3, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":[],"metadata":{"id":"8rUkkrij7JJX","executionInfo":{"status":"ok","timestamp":1703162883479,"user_tz":-330,"elapsed":19,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# turning our model training code into python script(`engine.py`)"],"metadata":{"id":"jch7BIv-dqDV"}},{"cell_type":"code","source":["with open(Path(folder / 'engine.py'),'w') as f:\n","  f.write(\n","      \"\"\"\n","\n","# importing the essentials:\n","\n","# Args:\n","# supply model,train_dataloader,and test_dataloader\n","\n","import torch\n","import time\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","def model_train(model,train_dataloader,test_dataloader):\n","\n","  # compile the model:\n","  loss = torch.nn.CrossEntropyLoss()\n","  optimizer = torch.optim.Adam(params=model.parameters(),\n","                              lr=0.001)\n","  def accuracy(pred,actual):\n","    correct = torch.eq(pred,actual).sum().item()\n","    acc = correct/len(actual)\n","    return acc\n","\n","  # fit the model\n","  def total_time(start,end):\n","    total_time = end-start\n","    print(\"Total Running TIME: {}\".format(total_time))\n","\n","  torch.manual_seed(42)\n","  torch.cuda.manual_seed(42)\n","\n","  epochs = 5\n","  start = time.perf_counter()\n","\n","  trl = []\n","  tsl = []\n","  tra = []\n","  tsa = []\n","  history = []\n","\n","  for epoch in range(epochs):\n","\n","    a_train_loss,a_test_loss,a_train_acc,a_test_acc = 0,0,0,0\n","\n","    for x_train,y_train in train_dataloader:\n","      x_train,y_train = x_train.to(device),y_train.to(device)\n","\n","      train_logits = model(x_train)\n","      train_predictions = train_logits.argmax(dim=1)\n","      train_actuals = y_train\n","      train_loss = loss(train_logits,train_actuals)\n","      train_accuracy = accuracy(train_predictions,train_actuals)\n","      a_train_loss += train_loss\n","      a_train_acc += train_accuracy\n","\n","      # zero grad the optimizer\n","      optimizer.zero_grad()\n","\n","      # backpropogate the train_loss\n","      train_loss.backward()\n","\n","      # step the optimizer up a notch\n","      optimizer.step()\n","\n","    # normalizing the accumulated losses and accuracies\n","    a_train_loss /= len(train_dataloader)\n","    a_train_acc /= len(train_dataloader)\n","\n","    # evaluate\n","    model.eval()\n","    with torch.inference_mode():\n","      for x_test,y_test in test_dataloader:\n","        x_test,y_test = x_test.to(device),y_test.to(device)\n","\n","        test_logits = model(x_test)\n","        test_predictions = test_logits.argmax(dim=1)\n","        test_actuals = y_test\n","        test_loss = loss(test_logits,test_predictions)\n","        test_accuracy = accuracy(test_predictions,test_actuals)\n","        a_test_loss += test_loss\n","        a_test_acc += test_accuracy\n","\n","      # normalizing the accumulated test loss and test accuracy\n","      a_test_loss /= len(test_dataloader)\n","      a_test_acc /= len(test_dataloader)\n","\n","\n","      # inserting the essentials in the container\n","      trl.append(a_train_loss)\n","      tsl.append(a_test_loss)\n","      tra.append(a_train_acc)\n","      tsa.append(a_test_acc)\n","\n","      print(\"Epoch: {} | Train Loss: {:.3f}, Train Acc: {:.3f} | Test Loss: {:.3f},Test Acc: {:.3f}\"\n","      .format(epoch,a_train_loss,a_train_acc,a_test_loss,a_test_acc))\n","\n","  end = time.perf_counter()\n","  total_time(start,end)\n","  return history.extend([trl,tra,tsl,tsa])\n","\"\"\"\n","\n","  )"],"metadata":{"id":"zrHwSo2BdqGy","executionInfo":{"status":"ok","timestamp":1703165098951,"user_tz":-330,"elapsed":455,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# import the engine module\n","from going_modular import engine"],"metadata":{"id":"2DvaCv_ViBO_","executionInfo":{"status":"ok","timestamp":1703165527506,"user_tz":-330,"elapsed":488,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# train the model with engine.py script that we have created!\n","engine.model_train(model1,train_dataloader,test_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxGd48SIk4v_","executionInfo":{"status":"ok","timestamp":1703165586795,"user_tz":-330,"elapsed":19763,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}},"outputId":"33db4642-178f-4920-c6c4-339053add9f1"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0 | Train Loss: 1.227, Train Acc: 0.379 | Test Loss: 0.469,Test Acc: 0.260\n","Epoch: 1 | Train Loss: 1.222, Train Acc: 0.293 | Test Loss: 0.961,Test Acc: 0.402\n","Epoch: 2 | Train Loss: 1.127, Train Acc: 0.305 | Test Loss: 0.989,Test Acc: 0.381\n","Epoch: 3 | Train Loss: 1.096, Train Acc: 0.301 | Test Loss: 0.963,Test Acc: 0.402\n","Epoch: 4 | Train Loss: 1.095, Train Acc: 0.348 | Test Loss: 0.979,Test Acc: 0.392\n","Total Running TIME: 19.157911669999976\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"puZqPFJ5nUKt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# create a python script for saving our model(`utils.py`)"],"metadata":{"id":"kfy4ZWJ6li-7"}},{"cell_type":"code","source":["with open(Path(folder / 'utils.py'),'w') as f:\n","  f.write(\n","\"\"\"\n","# importing the essentials:\n","from pathlib import Path\n","import torch\n","\n","def save_model(model_name):\n","\n","  saved_path = Path('SavedModels')\n","\n","  # make a directory\n","  saved_path.mkdir(parents=True,exist_ok=True)\n","\n","  # adding the .pth extension if model_name is provided without it\n","\n","  if model_name[-4:] != '.pth':\n","    model_name = model_name + '.pth'\n","\n","  # creating the model saved path\n","  model_saved_path = saved_path / model_name\n","\n","  # save the model\n","  saved_model = torch.save(obj=model0.state_dict(),\n","                          f=model_saved_path)\n","\n","  return saved_model\n","\n","\"\"\"\n","  )"],"metadata":{"id":"LVjT-QM_lq9M","executionInfo":{"status":"ok","timestamp":1703167064827,"user_tz":-330,"elapsed":905,"user":{"displayName":"george emmanuel","userId":"18047942969920931469"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iaxd2o_Mq3yk"},"execution_count":null,"outputs":[]}]}